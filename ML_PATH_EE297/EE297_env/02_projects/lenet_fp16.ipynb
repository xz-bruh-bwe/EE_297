{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ed3732-e5ff-4b89-9936-528b73511ebe",
   "metadata": {},
   "source": [
    "Building Basic LeNet for MNIST\n",
    "1. Make sure to run the helper functions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfff640e-2fcf-4973-a22a-fb36b0784f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PIP INSTALLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419c7de1-859e-4c06-bdf7-c1d56e6fa650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 86B0-AFDD\n",
      "\n",
      " Directory of C:\\Users\\Baron\\Desktop\\EE_297_Repo\\EE_297\\ML_PATH_EE297\\EE297_env\\projects\n",
      "\n",
      "04/12/2025  08:33 PM    <DIR>          .\n",
      "04/12/2025  08:33 PM    <DIR>          ..\n",
      "04/12/2025  08:33 PM    <DIR>          .ipynb_checkpoints\n",
      "03/22/2025  11:41 PM    <DIR>          Archive\n",
      "04/07/2025  10:48 PM            93,432 Lenet Design.ipynb\n",
      "04/12/2025  08:32 PM               337 lenet_fp16.ipynb\n",
      "04/04/2025  08:27 PM            42,485 lenet_model.png\n",
      "04/05/2025  11:49 PM    <DIR>          models\n",
      "04/07/2025  09:41 PM    <DIR>          pics_test_files\n",
      "04/07/2025  07:30 PM    <DIR>          prelims\n",
      "04/07/2025  12:21 AM    <DIR>          weights\n",
      "               3 File(s)        136,254 bytes\n",
      "               8 Dir(s)  169,383,006,208 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f7ef67-00fc-4c5d-8caa-5f668842f816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\ML_PATH_EE297\\\\EE297_env\\\\projects'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757d4d5f-b66c-4105-9042-b34a9d97e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\Users\\Baron\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "# Main Imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd18814-d67a-45f2-97d8-409711673d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab15d85-5fa8-4b90-8b87-a10cc0d8a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24aad44b-1e13-48b0-931f-fb857eac0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "#For Confusion Matrix\n",
    "y_test_raw = y_test\n",
    "\n",
    "# Converts the output data to categorical Data.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7125ab3e-d96d-49ef-b298-a60bbe87f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LeNet model with explicit dtype\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1),\n",
    "                  padding='same', dtype='float32'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), dtype='float32'),\n",
    "    layers.Conv2D(16, kernel_size=(5, 5), activation='relu', dtype='float32'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), dtype='float32'),\n",
    "    layers.Flatten(dtype='float32'),\n",
    "    layers.ReLU(max_value=6.0),\n",
    "    layers.Dense(120, activation=None, dtype='float32'),\n",
    "    layers.Dense(84, activation='relu', dtype='float32'),\n",
    "    layers.Dense(10, activation='softmax', dtype='float32')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9401f28-0443-46b9-8c48-f5532b4126e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c885e919-af1b-4d1f-bda3-0f86e33226f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 9s 18ms/step - loss: 0.2695 - accuracy: 0.9218 - val_loss: 0.0772 - val_accuracy: 0.9772\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0806 - accuracy: 0.9753 - val_loss: 0.0686 - val_accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 0.0469 - val_accuracy: 0.9872\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0456 - val_accuracy: 0.9872\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.0452 - val_accuracy: 0.9885\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.0384 - val_accuracy: 0.9887\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 7s 18ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0506 - val_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0451 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0490 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2415d297890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb69bc7f-f043-4f0b-8aff-5d346d81bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9878\n",
      "Test accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777d2bef-eeb4-4ac2-81bf-f97d30290082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_2             | Has weights? ✅\n",
      "max_pooling2d_2      | Has weights? ❌\n",
      "conv2d_3             | Has weights? ✅\n",
      "max_pooling2d_3      | Has weights? ❌\n",
      "flatten_1            | Has weights? ❌\n",
      "re_lu                | Has weights? ❌\n",
      "dense_3              | Has weights? ✅\n",
      "dense_4              | Has weights? ✅\n",
      "dense_5              | Has weights? ✅\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    has_weights = \"✅\" if layer.get_weights() else \"❌\"\n",
    "    print(f\"{layer.name:20s} | Has weights? {has_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3db7cf-847d-424d-ab2d-d3215e135fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "conv2d_2 weights shape: (5, 5, 1, 6)\n",
      "conv2d_2 biases shape: (6,)\n",
      "1\n",
      "conv2d_3 weights shape: (5, 5, 6, 16)\n",
      "conv2d_3 biases shape: (16,)\n",
      "2\n",
      "dense_3 weights shape: (400, 120)\n",
      "dense_3 biases shape: (120,)\n",
      "3\n",
      "dense_4 weights shape: (120, 84)\n",
      "dense_4 biases shape: (84,)\n",
      "4\n",
      "dense_5 weights shape: (84, 10)\n",
      "dense_5 biases shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Extract The Weights\n",
    "x = 0\n",
    "for layer in model.layers:\n",
    "    if layer.get_weights():\n",
    "        print(x)\n",
    "        w, b = layer.get_weights()\n",
    "        print(f\"{layer.name} weights shape: {w.shape}\")\n",
    "        print(f\"{layer.name} biases shape: {b.shape}\")\n",
    "        x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e712ded1-66be-4bf5-94b2-9dd7a8bd71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1), padding='same', dtype='float32')\n",
    "MAX_VAL = 31.984375\n",
    "MIN_VAL = -32.0\n",
    "weights = model.get_weights()\n",
    "\n",
    "#conv1_weights = weights[0]\n",
    "#conv1_biases = weights[1]\n",
    "conv1_weights = np.clip(weights[0], MIN_VAL, MAX_VAL)\n",
    "conv1_biases = np.clip(weights[1], MIN_VAL, MAX_VAL)\n",
    "\n",
    "#conv2_weights = weights[2]\n",
    "#conv2_biases = weights[3]\n",
    "conv2_weights = np.clip(weights[2], MIN_VAL, MAX_VAL)\n",
    "conv2_biases = np.clip(weights[3], MIN_VAL, MAX_VAL)\n",
    "\n",
    "#fc1_weights = weights[4]\n",
    "#fc1_biases = weights[5]\n",
    "fc1_weights = np.clip(weights[4], MIN_VAL, MAX_VAL)\n",
    "fc1_biases = np.clip(weights[5], MIN_VAL, MAX_VAL)\n",
    "\n",
    "#fc2_weights = weights[6]\n",
    "#fc2_biases = weights[7]\n",
    "fc2_weights = np.clip(weights[6], MIN_VAL, MAX_VAL)\n",
    "fc2_biases = np.clip(weights[7], MIN_VAL, MAX_VAL)\n",
    "\n",
    "#fc3_weights = weights[8]\n",
    "#fc3_biases = weights[9]\n",
    "fc3_weights = np.clip(weights[8], MIN_VAL, MAX_VAL)\n",
    "fc3_biases = np.clip(weights[9], MIN_VAL, MAX_VAL)\n",
    "\n",
    "#print(conv1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "178d1b72-a2db-4e76-b4b0-f6cf51483e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the current weights and biases to header files for HLS env\n",
    "import numpy as np\n",
    "\n",
    "# Load trained weights\n",
    "\n",
    "# Manually save the weights as c header files: \n",
    "# Export as C header\n",
    "## ---------------------------- ** CONV1 ** ---------------------------------------\n",
    "with open(\"weights/conv1_weights.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"data_t conv1_weights[5][5][1][6] = {\\n\")\n",
    "    for i in range(5):\n",
    "        f.write(\"  {\\n\")\n",
    "        for j in range(5):\n",
    "            f.write(\"    {\")\n",
    "            f.write(\", \".join(f\"{conv1_weights[i][j][0][k]:.4f}\" for k in range(6)))\n",
    "            f.write(\"},\\n\")\n",
    "        f.write(\"  },\\n\")\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "with open(\"weights/conv1_biases.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"data_t conv1_biases[6] = {\")\n",
    "    f.write(\", \".join(f\"{b:.8f}\" for b in conv1_biases))\n",
    "    f.write(\"};\\n\")\n",
    "## ---------------------------- ** COVN2 ** ---------------------------------------\n",
    "# Load trained weights\n",
    "\n",
    "# Save conv2_weights: shape (5, 5, 6, 16)\n",
    "with open(\"weights/conv2_weights.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"data_t conv2_weights[5][5][6][16] = {\\n\")\n",
    "    for i in range(5):\n",
    "        f.write(\"  {\\n\")\n",
    "        for j in range(5):\n",
    "            f.write(\"    {\\n\")\n",
    "            for k in range(6):\n",
    "                line = \"      {\" + \", \".join(f\"{conv2_weights[i][j][k][m]:.4f}\" for m in range(16)) + \"},\\n\"\n",
    "                f.write(line)\n",
    "            f.write(\"    },\\n\")\n",
    "        f.write(\"  },\\n\")\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "# Save conv2_biases: shape (16,)\n",
    "with open(\"weights/conv2_biases.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"data_t conv2_biases[16] = {\")\n",
    "    f.write(\", \".join(f\"{b:.4f}\" for b in conv2_biases))\n",
    "    f.write(\"};\\n\")\n",
    "## ---------------------------- ** FC1 ** ---------------------------------------\n",
    "\n",
    "# Save fc1_weights: shape (400, 120)\n",
    "with open(\"weights/fc1_weights.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc1_weights[400][120] = {\\n\")\n",
    "    for i in range(400):\n",
    "        f.write(\"  {\" + \", \".join(f\"{fc1_weights[i][j]:.4f}\" for j in range(120)) + \"},\\n\")\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "# Save fc1_biases: shape (120,)\n",
    "with open(\"weights/fc1_biases.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc1_biases[120] = {\")\n",
    "    f.write(\", \".join(f\"{b:.4f}\" for b in fc1_biases))\n",
    "    f.write(\"};\\n\")\n",
    "## ---------------------------- ** FC2 ** ---------------------------------------\n",
    "\n",
    "# Save fc2_weights: shape (120, 84)\n",
    "with open(\"weights/fc2_weights.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc2_weights[120][84] = {\\n\")\n",
    "    for i in range(120):\n",
    "        f.write(\"  {\" + \", \".join(f\"{fc2_weights[i][j]:.4f}\" for j in range(84)) + \"},\\n\")\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "# Save fc2_biases: shape (84,)\n",
    "with open(\"weights/fc2_biases.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc2_biases[84] = {\")\n",
    "    f.write(\", \".join(f\"{b:.4f}\" for b in fc2_biases))\n",
    "    f.write(\"};\\n\")\n",
    "## ---------------------------- ** FC3 ** ---------------------------------------\n",
    "    \n",
    "# Save fc3_weights: shape (84, 10)\n",
    "with open(\"weights/fc3_weights.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc3_weights[84][10] = {\\n\")\n",
    "    for i in range(84):\n",
    "        f.write(\"  {\" + \", \".join(f\"{fc3_weights[i][j]:.4f}\" for j in range(10)) + \"},\\n\")\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "# Save fc3_biases: shape (10,)\n",
    "with open(\"weights/fc3_biases.h\", \"w\") as f:\n",
    "    f.write('#include \"C:\\\\Users\\\\Baron\\\\Desktop\\\\EE_297_Repo\\\\EE_297\\\\vivado\\\\lenet_proj\\\\lenet_top.h\"\\n\\n') \n",
    "    f.write(\"float fc3_biases[10] = {\")\n",
    "    f.write(\", \".join(f\"{b:.4f}\" for b in fc3_biases))\n",
    "    f.write(\"};\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14ca58d3-8129-4579-85d6-f13424ae1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_lenet_fp16.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_lenet_fp16.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the newly created model to the side.\n",
    "# Save the trained model to an HDF5 file\n",
    "model.save('models/model_lenet_fp16.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5677e023-6ba2-450d-a7e5-e323aeae4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "## First layer:\n",
    "from tensorflow.keras.models import load_model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load the test image (if from txt file used in HLS)\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\")  # or whatever index you're using\n",
    "image = image.reshape(1, 28, 28, 1)  # Add batch and channel dimensions\n",
    "\n",
    "layer_output_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "# Get the output\n",
    "conv1_output = layer_output_model.predict(image)\n",
    "\n",
    "with open(\"prelims/conv1_out.txt\", \"w\") as f:\n",
    "    for filt in range(6):\n",
    "        #f.write(f\"==== Feature Map for Filter {filt} ====\\n\")\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                f.write(f\"{conv1_output[0, i, j, filt]:.4f} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3415cee9-fadc-4d46-b0eb-183ef41bea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "## Layer Second\n",
    "    # layers.MaxPooling(pool_size=(2, 2), dtype='float32')\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load the same input image used in HLS\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "# Get the output from the MaxPooling2D layer (after Conv2D)\n",
    "# Assuming it's the second layer (index 1)\n",
    "pool1_output_model = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "\n",
    "# Get the pooled output\n",
    "pool1_output = pool1_output_model.predict(image)  # Shape: (1, 14, 14, 6)\n",
    "\n",
    "# Save to text file (14x14x6 format)\n",
    "with open(\"prelims/pool1_out.txt\", \"w\") as f:\n",
    "    for filt in range(pool1_output.shape[3]):\n",
    "        for i in range(pool1_output.shape[1]):\n",
    "            for j in range(pool1_output.shape[2]):\n",
    "                f.write(f\"{pool1_output[0, i, j, filt]:.6f} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")  # separate each feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436af6c4-8306-448c-92d0-a16457329bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "### Third Layer\n",
    "    #**layers.Conv2D(16, kernel_size=(5, 5), activation='relu', dtype='float32'),\n",
    "# Load trained LeNet model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load and reshape the input image (same used in HLS)\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "# Build a model to output from the second Conv2D layer\n",
    "# Assuming layer 2 is the second Conv2D (after MaxPool)\n",
    "#model.summary()  # Use this to verify layer index if needed\n",
    "\n",
    "conv2_model = tf.keras.Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "\n",
    "# Run inference\n",
    "conv2_output = conv2_model.predict(image)  # Shape: (1, 10, 10, 16)\n",
    "\n",
    "# Save to .txt file for comparison with HLS output\n",
    "with open(\"prelims/conv2_out.txt\", \"w\") as f:\n",
    "    for filt in range(conv2_output.shape[3]):         # 16 filters\n",
    "        for i in range(conv2_output.shape[1]):        # 10 rows\n",
    "            for j in range(conv2_output.shape[2]):    # 10 cols\n",
    "                f.write(f\"{conv2_output[0, i, j, filt]:.6f} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")  # blank line between filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c6ad62d-c1f6-403e-9c7d-122adb2eadfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024167089080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024167089080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "## Fourth Layer\n",
    "##* layers.MaxPooling2D(pool_size=(2, 2), dtype='float32'), \n",
    "# Load your trained LeNet model\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load and reshape input image\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "# Extract output of second MaxPooling2D (index 3)\n",
    "pool2_model = tf.keras.Model(inputs=model.input, outputs=model.layers[3].output)\n",
    "\n",
    "# Run inference\n",
    "pool2_output = pool2_model.predict(image)  # Shape: (1, 5, 5, 16)\n",
    "\n",
    "# Save to .txt file\n",
    "with open(\"prelims/pool2_out.txt\", \"w\") as f:\n",
    "    for filt in range(16):\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                f.write(f\"{pool2_output[0, i, j, filt]:.6f} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c3b5ae-7404-47ed-967c-a9df139e7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000241670B2200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000241670B2200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fifth Layer\n",
    "#** layers.Flatten(dtype='float32'), \n",
    "# Load trained LeNet model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load and reshape the test image\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "\n",
    "# Build a model that outputs the Flatten layer\n",
    "flatten_model = tf.keras.Model(inputs=model.input, outputs=model.layers[4].output)\n",
    "\n",
    "# Run the image through the model\n",
    "flatten_output = flatten_model.predict(image)  # Shape: (1, 400)\n",
    "\n",
    "# Save to file\n",
    "with open(\"prelims/flatten_out.txt\", \"w\") as f:\n",
    "    for val in flatten_output[0]:  # access the single sample\n",
    "        f.write(f\"{val:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d045c60-9e23-4657-aa03-035feb2c0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# Sixth Layer (Dense Layer 1)\n",
    "# Load trained LeNet model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load and reshape the test image\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "# Build a model that outputs the first fully connected (Dense) layer, which is typically layer[6] in LeNet\n",
    "fc1_model = tf.keras.Model(inputs=model.input, outputs=model.layers[5].output)\n",
    "\n",
    "# Run the image through the model\n",
    "fc1_output = fc1_model.predict(image)  # Shape: (1, 120)\n",
    "\n",
    "# Save to file\n",
    "with open(\"prelims/fc1_out.txt\", \"w\") as f:\n",
    "    for val in fc1_output[0]:  # access the single sample\n",
    "        f.write(f\"{val:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b07e624b-a007-4331-9b09-7eaf1d0969e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "# Seven Layer (Dense Layer 2)\n",
    "# Load trained LeNet model\n",
    "model = tf.keras.models.load_model('models/model_lenet.h5py')\n",
    "\n",
    "# Load and reshape the test image\n",
    "image = np.loadtxt(\"pics_test_files/img_5.txt\").reshape(1, 28, 28, 1)\n",
    "\n",
    "# Build a model that outputs the first fully connected (Dense) layer, which is typically layer[6] in LeNet\n",
    "fc2_model = tf.keras.Model(inputs=model.input, outputs=model.layers[6].output)\n",
    "\n",
    "# Run the image through the model\n",
    "fc2_output = fc2_model.predict(image)  # Shape: (1, 120)\n",
    "\n",
    "# Save to file\n",
    "with open(\"prelims/fc2_out.txt\", \"w\") as f:\n",
    "    for val in fc2_output[0]:  # access the single sample\n",
    "        f.write(f\"{val:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a80a4-b900-47a8-a370-e516922921a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
