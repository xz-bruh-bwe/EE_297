{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2840219,"sourceType":"datasetVersion","datasetId":1724942},{"sourceId":395008,"sourceType":"modelInstanceVersion","modelInstanceId":324647,"modelId":345458}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\nimport shutil\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:18:32.662927Z","iopub.execute_input":"2025-05-18T07:18:32.663109Z","iopub.status.idle":"2025-05-18T07:18:46.517924Z","shell.execute_reply.started":"2025-05-18T07:18:32.663092Z","shell.execute_reply":"2025-05-18T07:18:46.517368Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the dataset","metadata":{}},{"cell_type":"code","source":"IMAGE_FOLDER = \"tusimple_processed/images\"\nMASK_FOLDER = \"tusimple_processed/masks\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:18:46.519394Z","iopub.execute_input":"2025-05-18T07:18:46.519821Z","iopub.status.idle":"2025-05-18T07:18:46.523258Z","shell.execute_reply.started":"2025-05-18T07:18:46.519802Z","shell.execute_reply":"2025-05-18T07:18:46.522518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dirs_if_not_exist(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n        print(\"Directory created:\", path)\n    else:\n        print(\"Directory already exists:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:18:46.523973Z","iopub.execute_input":"2025-05-18T07:18:46.524227Z","iopub.status.idle":"2025-05-18T07:18:46.555073Z","shell.execute_reply.started":"2025-05-18T07:18:46.524198Z","shell.execute_reply":"2025-05-18T07:18:46.554129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_dirs_if_not_exist(IMAGE_FOLDER)\ncreate_dirs_if_not_exist(MASK_FOLDER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:18:46.555954Z","iopub.execute_input":"2025-05-18T07:18:46.556276Z","iopub.status.idle":"2025-05-18T07:18:46.570725Z","shell.execute_reply.started":"2025-05-18T07:18:46.556213Z","shell.execute_reply":"2025-05-18T07:18:46.570224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Copy Images to the Image Directory","metadata":{}},{"cell_type":"code","source":"CLIPS_PATH = \"/kaggle/input/tusimple/TUSimple/train_set/clips\"\n\n# iterate through each directory\nfor clip_dir in os.listdir(CLIPS_PATH):\n    clip_dir_path = os.path.join(CLIPS_PATH, clip_dir)\n\n    print(\"Processing Clip:\", clip_dir)\n    # iterate through each sub directory\n    for frame_dir in os.listdir(clip_dir_path):\n        frame_path = os.path.join(clip_dir_path, frame_dir, \"20.jpg\")\n\n        # check if file is present\n        if not os.path.isfile(frame_path):\n            continue\n\n        # create new filename based on last 2 directory names\n        tmp = frame_path[:-7].split('/')[-2:]\n        new_filename = f\"{tmp[0]}_{tmp[1]}.jpg\"\n        new_file_path = os.path.join(IMAGE_FOLDER, new_filename)\n\n        # copy the file\n        shutil.copy(frame_path, new_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:18:46.571217Z","iopub.execute_input":"2025-05-18T07:18:46.571478Z","iopub.status.idle":"2025-05-18T07:19:28.144849Z","shell.execute_reply.started":"2025-05-18T07:18:46.571455Z","shell.execute_reply":"2025-05-18T07:19:28.144028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Total images in dataset:\", len(os.listdir(IMAGE_FOLDER)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:28.145753Z","iopub.execute_input":"2025-05-18T07:19:28.146073Z","iopub.status.idle":"2025-05-18T07:19:28.152716Z","shell.execute_reply.started":"2025-05-18T07:19:28.146041Z","shell.execute_reply":"2025-05-18T07:19:28.152022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create Masks for the Images","metadata":{}},{"cell_type":"code","source":"# load the dataset json files\ndf1 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0313.json\", lines = True)\ndf2 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0531.json\", lines = True)\ndf3 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0601.json\", lines = True)\n\n# combine into single dataframe\ndf = pd.concat([df1, df2, df3])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:28.156448Z","iopub.execute_input":"2025-05-18T07:19:28.156678Z","iopub.status.idle":"2025-05-18T07:19:28.336881Z","shell.execute_reply.started":"2025-05-18T07:19:28.156662Z","shell.execute_reply":"2025-05-18T07:19:28.336115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create function for generating masks\ndef generate_lane_mask(row):\n    # create a mask of all zeros\n    mask = np.zeros((728, 1280, 1), dtype=np.uint8)\n\n    # extract data from the row\n    h_samples = row.h_samples\n    lanes = row.lanes\n    raw_file = row.raw_file\n\n    # create mask: lane = 1, non-lane = 0\n    for lane in lanes:\n        # exclude -2 datapoints\n        h_samples_filtered = [y for x, y in zip(lane, h_samples) if x != -2]\n        lane_filtered = [x for x in lane if x != -2]\n\n        # create array of lane points\n        lane_points = np.array(list(zip(lane_filtered, h_samples_filtered)))\n\n        # update lane mask\n        cv2.polylines(mask, [lane_points], isClosed = False, color = (255, 255, 255), thickness = 15)\n    \n    # generate mask filename\n    temp = raw_file[:-7].split('/')[-2:]\n    mask_filename = f\"{temp[0]}_{temp[1]}.jpg\"\n    mask_filename_path = os.path.join(MASK_FOLDER, mask_filename)\n\n    # write the mask image\n    cv2.imwrite(mask_filename_path, mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:28.337846Z","iopub.execute_input":"2025-05-18T07:19:28.338157Z","iopub.status.idle":"2025-05-18T07:19:28.347704Z","shell.execute_reply.started":"2025-05-18T07:19:28.33813Z","shell.execute_reply":"2025-05-18T07:19:28.346774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# generate masks\nfor index, row in tqdm(df.iterrows(), total=len(df)):\n    generate_lane_mask(row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:28.348467Z","iopub.execute_input":"2025-05-18T07:19:28.348745Z","iopub.status.idle":"2025-05-18T07:19:35.580218Z","shell.execute_reply.started":"2025-05-18T07:19:28.348722Z","shell.execute_reply":"2025-05-18T07:19:35.579402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Total masks in dataset:\", len(os.listdir(MASK_FOLDER)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:35.58104Z","iopub.execute_input":"2025-05-18T07:19:35.58134Z","iopub.status.idle":"2025-05-18T07:19:35.588413Z","shell.execute_reply.started":"2025-05-18T07:19:35.581316Z","shell.execute_reply":"2025-05-18T07:19:35.587567Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"def visualize_image(image_name):\n    # get paths\n    image_path = os.path.join(IMAGE_FOLDER, image_name)\n    mask_path = os.path.join(MASK_FOLDER, image_name)\n    \n    # read the image and mask\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    mask = cv2.imread(mask_path)\n    \n    # plot the image\n    plt.figure(figsize = (20, 8))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title(\"Road Image\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(mask, cmap=\"gray\")\n    plt.title(\"Ground Truth Mask\")\n    \n    # show the images\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:35.589208Z","iopub.execute_input":"2025-05-18T07:19:35.589703Z","iopub.status.idle":"2025-05-18T07:19:35.63757Z","shell.execute_reply.started":"2025-05-18T07:19:35.58968Z","shell.execute_reply":"2025-05-18T07:19:35.636816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(5):\n    image_name = random.choice(os.listdir(IMAGE_FOLDER))\n    visualize_image(image_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:35.638306Z","iopub.execute_input":"2025-05-18T07:19:35.638489Z","iopub.status.idle":"2025-05-18T07:19:38.750887Z","shell.execute_reply.started":"2025-05-18T07:19:35.638475Z","shell.execute_reply":"2025-05-18T07:19:38.750129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Process Data for Training and Testing","metadata":{}},{"cell_type":"code","source":"train_image_folder = \"tusimple_processed/train/images\"\ntest_image_folder = \"tusimple_processed/test/images\"\ntrain_mask_folder = \"tusimple_processed/train/masks\"\ntest_mask_folder = \"tusimple_processed/test/masks\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:38.751708Z","iopub.execute_input":"2025-05-18T07:19:38.751929Z","iopub.status.idle":"2025-05-18T07:19:38.755817Z","shell.execute_reply.started":"2025-05-18T07:19:38.751911Z","shell.execute_reply":"2025-05-18T07:19:38.755047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for folder_path in [train_image_folder, test_image_folder, train_mask_folder, test_mask_folder]:\n    create_dirs_if_not_exist(folder_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:38.756616Z","iopub.execute_input":"2025-05-18T07:19:38.756858Z","iopub.status.idle":"2025-05-18T07:19:38.772654Z","shell.execute_reply.started":"2025-05-18T07:19:38.756833Z","shell.execute_reply":"2025-05-18T07:19:38.772015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimages = [file for file in os.listdir(IMAGE_FOLDER) if file.endswith(\".jpg\")]\nmasks = [file for file in os.listdir(MASK_FOLDER) if file.endswith(\".jpg\")]\n\n# split for train and test\ntrain_images, test_images = train_test_split(images, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:38.773349Z","iopub.execute_input":"2025-05-18T07:19:38.773628Z","iopub.status.idle":"2025-05-18T07:19:39.194414Z","shell.execute_reply.started":"2025-05-18T07:19:38.773612Z","shell.execute_reply":"2025-05-18T07:19:39.193862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_images), len(test_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:39.19508Z","iopub.execute_input":"2025-05-18T07:19:39.195585Z","iopub.status.idle":"2025-05-18T07:19:39.200286Z","shell.execute_reply.started":"2025-05-18T07:19:39.195565Z","shell.execute_reply":"2025-05-18T07:19:39.199672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# move files to the corresponding folders\nfor file in train_images:\n    # move the image and mask\n    source = os.path.join(IMAGE_FOLDER, file)\n    destination = os.path.join(train_image_folder, file)\n    shutil.move(source, destination)\n    \n    source = os.path.join(MASK_FOLDER, file)\n    destination = os.path.join(train_mask_folder, file)\n    shutil.move(source, destination)\n\nfor file in test_images:\n    # move the image and mask\n    source = os.path.join(IMAGE_FOLDER, file)\n    destination = os.path.join(test_image_folder, file)\n    shutil.move(source, destination)\n    \n    source = os.path.join(MASK_FOLDER, file)\n    destination = os.path.join(test_mask_folder, file)\n    shutil.move(source, destination)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:39.200954Z","iopub.execute_input":"2025-05-18T07:19:39.201162Z","iopub.status.idle":"2025-05-18T07:19:39.388917Z","shell.execute_reply.started":"2025-05-18T07:19:39.201141Z","shell.execute_reply":"2025-05-18T07:19:39.388371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef load_image(image_path, mask_path):\n    size = [224, 224]\n    \n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, size)\n    image = image / 255.0  \n\n    \n    kernel = tf.constant([[0., -1., 0.],\n                          [-1., 5., -1.],\n                          [0., -1., 0.]], dtype=tf.float32)\n    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n\n    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n    sharpened_channels = []\n    for c in channels:\n        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n    image = tf.concat(sharpened_channels, axis=-1)\n    image = tf.clip_by_value(image, 0.0, 1.0)  \n\n  \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_jpeg(mask, channels=1)\n    mask = tf.image.resize(mask, size)\n    mask = mask / 255.0  \n    \n    return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:39.389564Z","iopub.execute_input":"2025-05-18T07:19:39.389743Z","iopub.status.idle":"2025-05-18T07:19:39.39605Z","shell.execute_reply.started":"2025-05-18T07:19:39.389728Z","shell.execute_reply":"2025-05-18T07:19:39.39523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dataset_from_folder(image_folder, mask_folder):\n    image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(\".jpg\")])\n    mask_files = sorted([os.path.join(mask_folder, file) for file in os.listdir(mask_folder) if file.endswith(\".jpg\")])\n\n    dataset = tf.data.Dataset.from_tensor_slices((image_files, mask_files))\n    dataset = dataset.map(lambda image_path, mask_path: load_image(image_path, mask_path))\n    \n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:39.396772Z","iopub.execute_input":"2025-05-18T07:19:39.397465Z","iopub.status.idle":"2025-05-18T07:19:39.411346Z","shell.execute_reply.started":"2025-05-18T07:19:39.397441Z","shell.execute_reply":"2025-05-18T07:19:39.410703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load dataset from folder\ntrain_dataset = dataset_from_folder(train_image_folder, train_mask_folder)\ntest_dataset = dataset_from_folder(test_image_folder, test_mask_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:39.411946Z","iopub.execute_input":"2025-05-18T07:19:39.412167Z","iopub.status.idle":"2025-05-18T07:19:40.540243Z","shell.execute_reply.started":"2025-05-18T07:19:39.412152Z","shell.execute_reply":"2025-05-18T07:19:40.539528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set config\nBATCH_SIZE = 16\nBUFFER_SIZE = 1000\n\n# optimize for performance improvement\ntrain_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_datset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:40.540924Z","iopub.execute_input":"2025-05-18T07:19:40.541101Z","iopub.status.idle":"2025-05-18T07:19:40.565681Z","shell.execute_reply.started":"2025-05-18T07:19:40.541087Z","shell.execute_reply":"2025-05-18T07:19:40.565154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_sample(image_list):\n    plt.figure(figsize=(10, 10))\n\n    titles = [\"Image\", \"True Mask\", \"Predicted Mask\"]\n\n    for i in range(len(image_list)):\n        plt.subplot(1, len(image_list), i+1)\n        plt.title(titles[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_list[i]))\n        plt.axis(\"off\")\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:40.568678Z","iopub.execute_input":"2025-05-18T07:19:40.56885Z","iopub.status.idle":"2025-05-18T07:19:40.573169Z","shell.execute_reply.started":"2025-05-18T07:19:40.568837Z","shell.execute_reply":"2025-05-18T07:19:40.572526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image, mask in train_dataset.take(1):\n    display_sample([image[0], mask[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:40.573996Z","iopub.execute_input":"2025-05-18T07:19:40.574263Z","iopub.status.idle":"2025-05-18T07:19:48.449406Z","shell.execute_reply.started":"2025-05-18T07:19:40.574246Z","shell.execute_reply":"2025-05-18T07:19:48.448808Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Creation - VGG-UNet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Input, Dropout, Activation, Add, BatchNormalization, Conv2D, Concatenate, UpSampling2D\nfrom tensorflow.keras.models import Model\n\ndef VGG16_UNet(input_shape=(None, None, 3)):\n    '''U net architechture with VGG16 encoder'''\n    def Conv2DReluBatchNorm(n_filters, kernel_size, stride, inputs):\n        x = Conv2D(n_filters, (1, 1), strides=1, \n                   padding=\"same\", kernel_initializer='glorot_normal', activation=\"elu\")(inputs)\n        x = Conv2D(n_filters, kernel_size, strides=stride, \n                   padding=\"same\", kernel_initializer='glorot_normal', activation=\"elu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(rate=0.25)(x, training=True) # traininig + test-time ropout!\n        return x\n        \n    # VGG16 encoder\n    vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n    \n    # Unfreeze VGG16 layers\n    for layer in vgg16.layers:\n        layer.trainable = True\n    \n    # Encoder layers\n    inputs = vgg16.input\n    layer1 = vgg16.get_layer(\"block1_conv2\").output\n    layer2 = vgg16.get_layer(\"block2_conv2\").output\n    layer3 = vgg16.get_layer(\"block3_conv3\").output\n    layer4 = vgg16.get_layer(\"block4_conv3\").output\n    layer5 = vgg16.get_layer(\"block5_conv3\").output\n\n    # Decoder layers\n    merge6 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer5), layer4])\n    layer6 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge6)\n\n    merge7 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer6), layer3])\n    layer7 = Conv2DReluBatchNorm(256, (3, 3), (1, 1), merge7)\n\n    merge8 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer7), layer2])\n    layer8 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge8)\n\n    merge9 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer8), layer1])\n    layer9 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge9)\n\n    output = Conv2D(1, (1, 1), strides=(1, 1), activation=\"sigmoid\", name=\"output\")(layer9)\n\n    return Model(inputs=inputs, outputs=output)\n\nmodel = VGG16_UNet(input_shape=(224, 224, 3)) # Adjust input shape as needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:48.450124Z","iopub.execute_input":"2025-05-18T07:19:48.450386Z","iopub.status.idle":"2025-05-18T07:19:54.120662Z","shell.execute_reply.started":"2025-05-18T07:19:48.450369Z","shell.execute_reply":"2025-05-18T07:19:54.120098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras import backend as K\n\ndef dice_coefficent(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    mu = y_pred[:, :, :, 0]\n    y_pred_f = K.flatten(mu)\n    intersection = K.sum(y_true_f * y_pred_f)\n    smooth = 1.0\n    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coefficent(y_true, y_pred)\n\ndef recall_smooth(y_true, y_pred):\n    y_pred_f = K.flatten(y_pred)\n    y_true_f = K.flatten(y_true)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection / (K.sum(y_true_f) + K.epsilon()))\n\ndef precision_smooth(y_true, y_pred):\n    y_pred_f = K.flatten(y_pred)\n    y_true_f = K.flatten(y_true)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection / (K.sum(y_true_f) + K.epsilon()))\n\ndef accuracy(y_true, y_pred):\n    y_pred_f = K.flatten(y_pred)\n    y_true_f = K.flatten(y_true)\n\n    # True positives\n    true_positives = K.sum(K.round(K.clip(y_true_f * y_pred_f, 0, 1)))\n    \n    # True negatives\n    true_negatives = K.sum(K.round(K.clip((1- y_true_f) * (1 - y_pred_f), 0, 1)))\n    \n    # Total pixels\n    total_pixels = K.cast(tensorflow.size(y_true_f), K.floatx())\n    \n    # Accuracy\n    accuracy_value = (true_positives + true_negatives) / total_pixels\n\n    return accuracy_value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:54.121401Z","iopub.execute_input":"2025-05-18T07:19:54.121654Z","iopub.status.idle":"2025-05-18T07:19:54.128688Z","shell.execute_reply.started":"2025-05-18T07:19:54.121633Z","shell.execute_reply":"2025-05-18T07:19:54.128055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer=\"adam\", loss=dice_loss, metrics=[dice_coefficent, precision_smooth, recall_smooth, accuracy])\nprint(f'Number of parameters: {model.count_params()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:54.129318Z","iopub.execute_input":"2025-05-18T07:19:54.129532Z","iopub.status.idle":"2025-05-18T07:19:54.153018Z","shell.execute_reply.started":"2025-05-18T07:19:54.129518Z","shell.execute_reply":"2025-05-18T07:19:54.152495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plot the model\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=False, dpi=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:54.153635Z","iopub.execute_input":"2025-05-18T07:19:54.15383Z","iopub.status.idle":"2025-05-18T07:19:54.525778Z","shell.execute_reply.started":"2025-05-18T07:19:54.153809Z","shell.execute_reply":"2025-05-18T07:19:54.525092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create mask from prediction\ndef create_mask(pred_mask):\n    # round to closest\n    pred_mask = tf.math.round(pred_mask)\n    return pred_mask\n\ndef show_predictions(dataset=None, num=1):\n    if dataset:\n        for images, masks in dataset.take(num):\n            pred_mask = model.predict(images)\n            pred_mask = create_mask(pred_mask[0])\n            display_sample([images[0], masks[0], pred_mask])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:54.526755Z","iopub.execute_input":"2025-05-18T07:19:54.527242Z","iopub.status.idle":"2025-05-18T07:19:54.532339Z","shell.execute_reply.started":"2025-05-18T07:19:54.527218Z","shell.execute_reply":"2025-05-18T07:19:54.531574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_predictions(train_dataset, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:19:54.533104Z","iopub.execute_input":"2025-05-18T07:19:54.533374Z","iopub.status.idle":"2025-05-18T07:20:42.532563Z","shell.execute_reply.started":"2025-05-18T07:19:54.53335Z","shell.execute_reply":"2025-05-18T07:20:42.531996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# callbacks and logs\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, Callback\nimport datetime\n\nclass DisplayCallback(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        show_predictions(test_dataset, 1)\n        print(f\"Sample Prediction after epoch {epoch}\\n\")\n\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\ncallbacks = [\n    DisplayCallback(), \n    TensorBoard(logdir, histogram_freq=-1),\n    EarlyStopping(patience=5, verbose=1),\n    ModelCheckpoint(\"best_model.keras\", verbose=1, save_best_only=True)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:20:42.533311Z","iopub.execute_input":"2025-05-18T07:20:42.533529Z","iopub.status.idle":"2025-05-18T07:20:42.540685Z","shell.execute_reply.started":"2025-05-18T07:20:42.533508Z","shell.execute_reply":"2025-05-18T07:20:42.540087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 10\nsteps_per_epoch = len(os.listdir(train_image_folder)) // BATCH_SIZE\nvalidation_steps = len(os.listdir(test_image_folder)) // BATCH_SIZE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:20:42.541338Z","iopub.execute_input":"2025-05-18T07:20:42.541501Z","iopub.status.idle":"2025-05-18T07:20:42.554561Z","shell.execute_reply.started":"2025-05-18T07:20:42.541488Z","shell.execute_reply":"2025-05-18T07:20:42.553986Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    validation_data=test_dataset,\n    epochs=EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:20:42.555226Z","iopub.execute_input":"2025-05-18T07:20:42.555417Z","iopub.status.idle":"2025-05-18T08:05:34.645343Z","shell.execute_reply.started":"2025-05-18T07:20:42.555403Z","shell.execute_reply":"2025-05-18T08:05:34.644794Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot the Metrics","metadata":{}},{"cell_type":"code","source":"# plot train and val accuracy\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n\n# plot train and val loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n\nplt.tight_layout()\nplt.savefig(\"training_history.svg\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:34.646205Z","iopub.execute_input":"2025-05-18T08:05:34.646445Z","iopub.status.idle":"2025-05-18T08:05:34.96851Z","shell.execute_reply.started":"2025-05-18T08:05:34.646428Z","shell.execute_reply":"2025-05-18T08:05:34.967824Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the Best Model","metadata":{}},{"cell_type":"code","source":"best_model = tf.keras.models.load_model(\n    \"best_model.keras\",\n    custom_objects={\n        \"dice_loss\": dice_loss,\n        \"dice_coefficent\": dice_coefficent,\n        \"precision_smooth\": precision_smooth,\n        \"recall_smooth\": recall_smooth,\n        \"accuracy\": accuracy\n    }\n)\nbest_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:34.969348Z","iopub.execute_input":"2025-05-18T08:05:34.969933Z","iopub.status.idle":"2025-05-18T08:05:35.977453Z","shell.execute_reply.started":"2025-05-18T08:05:34.969896Z","shell.execute_reply":"2025-05-18T08:05:35.976869Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Predictions","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import array_to_img\n\ndef save_prediction_plot(image_list, index=0, save_dir=\"prediction_plots\"):\n    os.makedirs(save_dir, exist_ok=True)\n    titles = [\"Image\", \"True Mask\", \"Predicted Mask\"]\n\n    plt.figure(figsize=(10, 10))\n    for i in range(len(image_list)):\n        plt.subplot(1, len(image_list), i + 1)\n        plt.title(titles[i])\n        plt.imshow(array_to_img(image_list[i]))\n        plt.axis(\"off\")\n\n    filepath = os.path.join(save_dir, f\"prediction_{index}.png\")\n    plt.savefig(filepath)\n    plt.close()\n    print(f\"✅ Prediction plot saved: {filepath}\")\n\ndef show_and_save_predictions(dataset=None, num=1, save_dir=\"prediction_plots\"):\n    if dataset:\n        os.makedirs(save_dir, exist_ok=True)\n        for i, (images, masks) in enumerate(dataset.take(num)):\n            pred_mask = model.predict(images)\n            pred_mask = create_mask(pred_mask[0])\n            display_sample([images[0], masks[0], pred_mask])\n            save_prediction_plot([images[0], masks[0], pred_mask], index=i, save_dir=save_dir)\n\nshow_and_save_predictions(test_dataset, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:35.978124Z","iopub.execute_input":"2025-05-18T08:05:35.978353Z","iopub.status.idle":"2025-05-18T08:05:43.690682Z","shell.execute_reply.started":"2025-05-18T08:05:35.978337Z","shell.execute_reply":"2025-05-18T08:05:43.690017Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test from Image Path","metadata":{}},{"cell_type":"code","source":"def load_test_image(image_path):\n    size = [224, 224]\n    \n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, size)\n    image = image / 255.0 # normalize to [0, 1]\n\n    kernel = tf.constant([[0., -1., 0.],\n                          [-1., 5., -1.],\n                          [0., -1., 0.]], dtype=tf.float32)\n    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n\n    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n    sharpened_channels = []\n    for c in channels:\n        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n    image = tf.concat(sharpened_channels, axis=-1)\n    image = tf.clip_by_value(image, 0.0, 1.0)  \n    \n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:43.691696Z","iopub.execute_input":"2025-05-18T08:05:43.691899Z","iopub.status.idle":"2025-05-18T08:05:43.696022Z","shell.execute_reply.started":"2025-05-18T08:05:43.691883Z","shell.execute_reply":"2025-05-18T08:05:43.69536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_test_sample(image_list):\n    plt.figure(figsize=(10, 10))\n\n    titles = [\"Image\", \"Predicted Mask\"]\n\n    for i in range(len(image_list)):\n        plt.subplot(1, len(image_list), i+1)\n        plt.title(titles[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_list[i]))\n        plt.axis(\"off\")\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:43.696747Z","iopub.execute_input":"2025-05-18T08:05:43.697052Z","iopub.status.idle":"2025-05-18T08:05:43.707842Z","shell.execute_reply.started":"2025-05-18T08:05:43.697027Z","shell.execute_reply":"2025-05-18T08:05:43.70733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/tusimple/TUSimple/train_set/clips/0313-1/10000/20.jpg\"\nimage = load_test_image(image_path)\ntest_image = tf.expand_dims(image, axis=0)\npred_mask = model.predict([test_image])\npred_mask = create_mask(pred_mask[0])\n\ndisplay_test_sample([image, pred_mask])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:05:43.708403Z","iopub.execute_input":"2025-05-18T08:05:43.708569Z","iopub.status.idle":"2025-05-18T08:05:49.082093Z","shell.execute_reply.started":"2025-05-18T08:05:43.708549Z","shell.execute_reply":"2025-05-18T08:05:49.081334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convert Image Sequence to Video Using Opencv","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess_frame(image_path):\n    size = [224, 224]\n    \n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, size)\n    image = image / 255.0  # normalize to [0, 1]\n\n    kernel = tf.constant([[0., -1., 0.],\n                          [-1., 5., -1.],\n                          [0., -1., 0.]], dtype=tf.float32)\n    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n\n    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n    sharpened_channels = []\n    for c in channels:\n        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n    image = tf.concat(sharpened_channels, axis=-1)\n    image = tf.clip_by_value(image, 0.0, 1.0)  \n    \n    # Add batch dimension\n    image = tf.expand_dims(image, axis=0)\n    \n    return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = tf.math.round(pred_mask)\n    return pred_mask","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def postprocess_mask(pred_mask, original_frame):\n    pred_mask = pred_mask.numpy()\n    pred_mask = pred_mask[0, :, :, 0] if pred_mask.ndim == 4 else pred_mask[0]\n    pred_mask = (pred_mask * 255).astype(np.uint8)\n    pred_mask = cv2.resize(pred_mask, (original_frame.shape[1], original_frame.shape[0]))\n\n    # Create a blank image for the colored mask\n    mask_colored = np.zeros_like(original_frame)\n\n    # Yellow lane color (BGR): (0, 255, 255)\n    mask_colored[pred_mask > 0] = [0, 255, 255]\n\n    # Blend the original frame with the mask\n    blended = cv2.addWeighted(original_frame, 1.0, mask_colored, 0.6, 0)\n\n    return blended","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport os\n\n# Input and output paths\npath = \"/kaggle/input/tusimple/TUSimple/test_set/clips/0530/1492626265087865031_0\"\nout_path = \"imgToVid\"\nout_video_name = \"driving_car_lanes.mp4\"\nout_video_full_path = os.path.join(out_path, out_video_name)\n\n# Create output directory if it doesn't exist\nos.makedirs(out_path, exist_ok=True)\n\n# Load the Keras lane detection model (replace with your model path)\nmodel = load_model('best_model.keras', custom_objects={\n        \"dice_loss\": dice_loss,\n        \"dice_coefficent\": dice_coefficent,\n        \"precision_smooth\": precision_smooth,\n        \"recall_smooth\": recall_smooth,\n        \"accuracy\": accuracy\n    })  # Update with your model path\n\n# Get list of images and sort them\npre_imgs = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\npre_imgs.sort()\n\n# Full paths to images\nimg_paths = [os.path.join(path, i) for i in pre_imgs]\n\n# Read the first image to get size\nframe = cv2.imread(img_paths[0])\nif frame is None:\n    raise ValueError(f\"Failed to read first image: {img_paths[0]}\")\n\nheight, width = frame.shape[:2]\ncv2_fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nfps = 12\nvideo = cv2.VideoWriter(out_video_full_path, cv2_fourcc, fps, (width, height))\n\n# Process each frame\nfor img_path in img_paths:\n    frame = cv2.imread(img_path)\n    if frame is None:\n        print(f\"Warning: Could not read image {img_path}\")\n        continue\n    \n    input_frame = load_and_preprocess_frame(img_path)\n    \n    pred_mask = model.predict(input_frame, verbose=0)\n    pred_mask = create_mask(pred_mask)\n    \n    output_frame = postprocess_mask(pred_mask, frame)\n    \n    video.write(output_frame)\n\nvideo.release()\nprint(\"Video with masked lane predictions saved to:\", out_video_full_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import HTML\nfrom base64 import b64encode\n\ndef play(filename):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n    return HTML(html)\n\nplay(out_video_full_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T08:18:17.893017Z","iopub.execute_input":"2025-05-18T08:18:17.893316Z","iopub.status.idle":"2025-05-18T08:18:17.928193Z","shell.execute_reply.started":"2025-05-18T08:18:17.893297Z","shell.execute_reply":"2025-05-18T08:18:17.927376Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Packaging Model, Training Metrics, and Output Video into a ZIP File","metadata":{}},{"cell_type":"code","source":"import csv\n\nwith open(\"training_history.csv\", mode='w', newline='') as file:\n    writer = csv.writer(file)\n    # Write header\n    writer.writerow([\"Epoch\", \"Train_Loss\", \"Train_Accuracy\", \"Val_Loss\", \"Val_Accuracy\"])\n    \n    # Write data\n    for epoch in range(len(history.history['loss'])):\n        writer.writerow([\n            epoch + 1,\n            history.history['loss'][epoch],\n            history.history['accuracy'][epoch],\n            history.history['val_loss'][epoch],\n            history.history['val_accuracy'][epoch]\n        ])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nimport os\n\nfiles = [\n    \"training_history.csv\",\n    \"training_history.svg\",\n    \"best_model.keras\",\n    \"imgToVid/driving_car_lanes.mp4\"\n]\n\nplots_dir = \"prediction_plots\"\n\nzip_filename = \"model_and_metrics.zip\"\n\ndef add_file_to_zip(file_name, zipf):\n    zipf.write(file_name)\n    print(f\"✅ Added to zip: {file_name}\")\n\ndef add_folder_to_zip(directory, zipf):\n    for foldername, subfolders, filenames in os.walk(directory):\n        for filename in filenames:\n            filepath = os.path.join(foldername, filename)\n           \n            arcname = os.path.relpath(filepath, start=os.path.dirname(directory))\n            zipf.write(filepath, arcname=arcname)\n        print(f\"✅ Added to zip: {foldername}\")\n\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    for file in files:\n        add_file_to_zip(file, zipf)\n\n    add_folder_to_zip(plots_dir, zipf)\n\nprint(f\"✅ Zip created: {zip_filename} (includes model, metrics CSV, video, and prediction plots)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink, display, HTML\n\n# Create and display download link\ndisplay(FileLink(zip_filename))\n\ndisplay(HTML(\"<h3 style='color:red;'>⚠️ Don't forget to click and download the zip file before closing the session!</h3>\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}