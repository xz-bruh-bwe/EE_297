{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T07:18:32.663109Z",
     "iopub.status.busy": "2025-05-18T07:18:32.662927Z",
     "iopub.status.idle": "2025-05-18T07:18:46.517924Z",
     "shell.execute_reply": "2025-05-18T07:18:46.517368Z",
     "shell.execute_reply.started": "2025-05-18T07:18:32.663092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:18:46.519821Z",
     "iopub.status.busy": "2025-05-18T07:18:46.519394Z",
     "iopub.status.idle": "2025-05-18T07:18:46.523258Z",
     "shell.execute_reply": "2025-05-18T07:18:46.522518Z",
     "shell.execute_reply.started": "2025-05-18T07:18:46.519802Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = \"tusimple_processed/images\"\n",
    "MASK_FOLDER = \"tusimple_processed/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:18:46.524227Z",
     "iopub.status.busy": "2025-05-18T07:18:46.523973Z",
     "iopub.status.idle": "2025-05-18T07:18:46.555073Z",
     "shell.execute_reply": "2025-05-18T07:18:46.554129Z",
     "shell.execute_reply.started": "2025-05-18T07:18:46.524198Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dirs_if_not_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"Directory created:\", path)\n",
    "    else:\n",
    "        print(\"Directory already exists:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:18:46.556276Z",
     "iopub.status.busy": "2025-05-18T07:18:46.555954Z",
     "iopub.status.idle": "2025-05-18T07:18:46.570725Z",
     "shell.execute_reply": "2025-05-18T07:18:46.570224Z",
     "shell.execute_reply.started": "2025-05-18T07:18:46.556213Z"
    }
   },
   "outputs": [],
   "source": [
    "create_dirs_if_not_exist(IMAGE_FOLDER)\n",
    "create_dirs_if_not_exist(MASK_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Images to the Image Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:18:46.571478Z",
     "iopub.status.busy": "2025-05-18T07:18:46.571217Z",
     "iopub.status.idle": "2025-05-18T07:19:28.144849Z",
     "shell.execute_reply": "2025-05-18T07:19:28.144028Z",
     "shell.execute_reply.started": "2025-05-18T07:18:46.571455Z"
    }
   },
   "outputs": [],
   "source": [
    "CLIPS_PATH = \"/kaggle/input/tusimple/TUSimple/train_set/clips\"\n",
    "\n",
    "# iterate through each directory\n",
    "for clip_dir in os.listdir(CLIPS_PATH):\n",
    "    clip_dir_path = os.path.join(CLIPS_PATH, clip_dir)\n",
    "\n",
    "    print(\"Processing Clip:\", clip_dir)\n",
    "    # iterate through each sub directory\n",
    "    for frame_dir in os.listdir(clip_dir_path):\n",
    "        frame_path = os.path.join(clip_dir_path, frame_dir, \"20.jpg\")\n",
    "\n",
    "        # check if file is present\n",
    "        if not os.path.isfile(frame_path):\n",
    "            continue\n",
    "\n",
    "        # create new filename based on last 2 directory names\n",
    "        tmp = frame_path[:-7].split('/')[-2:]\n",
    "        new_filename = f\"{tmp[0]}_{tmp[1]}.jpg\"\n",
    "        new_file_path = os.path.join(IMAGE_FOLDER, new_filename)\n",
    "\n",
    "        # copy the file\n",
    "        shutil.copy(frame_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:28.146073Z",
     "iopub.status.busy": "2025-05-18T07:19:28.145753Z",
     "iopub.status.idle": "2025-05-18T07:19:28.152716Z",
     "shell.execute_reply": "2025-05-18T07:19:28.152022Z",
     "shell.execute_reply.started": "2025-05-18T07:19:28.146041Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total images in dataset:\", len(os.listdir(IMAGE_FOLDER)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Masks for the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:28.156678Z",
     "iopub.status.busy": "2025-05-18T07:19:28.156448Z",
     "iopub.status.idle": "2025-05-18T07:19:28.336881Z",
     "shell.execute_reply": "2025-05-18T07:19:28.336115Z",
     "shell.execute_reply.started": "2025-05-18T07:19:28.156662Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset json files\n",
    "df1 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0313.json\", lines = True)\n",
    "df2 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0531.json\", lines = True)\n",
    "df3 = pd.read_json(\"/kaggle/input/tusimple/TUSimple/train_set/label_data_0601.json\", lines = True)\n",
    "\n",
    "# combine into single dataframe\n",
    "df = pd.concat([df1, df2, df3])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:28.338157Z",
     "iopub.status.busy": "2025-05-18T07:19:28.337846Z",
     "iopub.status.idle": "2025-05-18T07:19:28.347704Z",
     "shell.execute_reply": "2025-05-18T07:19:28.346774Z",
     "shell.execute_reply.started": "2025-05-18T07:19:28.33813Z"
    }
   },
   "outputs": [],
   "source": [
    "# create function for generating masks\n",
    "def generate_lane_mask(row):\n",
    "    # create a mask of all zeros\n",
    "    mask = np.zeros((728, 1280, 1), dtype=np.uint8)\n",
    "\n",
    "    # extract data from the row\n",
    "    h_samples = row.h_samples\n",
    "    lanes = row.lanes\n",
    "    raw_file = row.raw_file\n",
    "\n",
    "    # create mask: lane = 1, non-lane = 0\n",
    "    for lane in lanes:\n",
    "        # exclude -2 datapoints\n",
    "        h_samples_filtered = [y for x, y in zip(lane, h_samples) if x != -2]\n",
    "        lane_filtered = [x for x in lane if x != -2]\n",
    "\n",
    "        # create array of lane points\n",
    "        lane_points = np.array(list(zip(lane_filtered, h_samples_filtered)))\n",
    "\n",
    "        # update lane mask\n",
    "        cv2.polylines(mask, [lane_points], isClosed = False, color = (255, 255, 255), thickness = 15)\n",
    "    \n",
    "    # generate mask filename\n",
    "    temp = raw_file[:-7].split('/')[-2:]\n",
    "    mask_filename = f\"{temp[0]}_{temp[1]}.jpg\"\n",
    "    mask_filename_path = os.path.join(MASK_FOLDER, mask_filename)\n",
    "\n",
    "    # write the mask image\n",
    "    cv2.imwrite(mask_filename_path, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:28.348745Z",
     "iopub.status.busy": "2025-05-18T07:19:28.348467Z",
     "iopub.status.idle": "2025-05-18T07:19:35.580218Z",
     "shell.execute_reply": "2025-05-18T07:19:35.579402Z",
     "shell.execute_reply.started": "2025-05-18T07:19:28.348722Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate masks\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    generate_lane_mask(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:35.58134Z",
     "iopub.status.busy": "2025-05-18T07:19:35.58104Z",
     "iopub.status.idle": "2025-05-18T07:19:35.588413Z",
     "shell.execute_reply": "2025-05-18T07:19:35.587567Z",
     "shell.execute_reply.started": "2025-05-18T07:19:35.581316Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total masks in dataset:\", len(os.listdir(MASK_FOLDER)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:35.589703Z",
     "iopub.status.busy": "2025-05-18T07:19:35.589208Z",
     "iopub.status.idle": "2025-05-18T07:19:35.63757Z",
     "shell.execute_reply": "2025-05-18T07:19:35.636816Z",
     "shell.execute_reply.started": "2025-05-18T07:19:35.58968Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_image(image_name):\n",
    "    # get paths\n",
    "    image_path = os.path.join(IMAGE_FOLDER, image_name)\n",
    "    mask_path = os.path.join(MASK_FOLDER, image_name)\n",
    "    \n",
    "    # read the image and mask\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path)\n",
    "    \n",
    "    # plot the image\n",
    "    plt.figure(figsize = (20, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Road Image\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    \n",
    "    # show the images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:35.638489Z",
     "iopub.status.busy": "2025-05-18T07:19:35.638306Z",
     "iopub.status.idle": "2025-05-18T07:19:38.750887Z",
     "shell.execute_reply": "2025-05-18T07:19:38.750129Z",
     "shell.execute_reply.started": "2025-05-18T07:19:35.638475Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    image_name = random.choice(os.listdir(IMAGE_FOLDER))\n",
    "    visualize_image(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:38.751929Z",
     "iopub.status.busy": "2025-05-18T07:19:38.751708Z",
     "iopub.status.idle": "2025-05-18T07:19:38.755817Z",
     "shell.execute_reply": "2025-05-18T07:19:38.755047Z",
     "shell.execute_reply.started": "2025-05-18T07:19:38.751911Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_folder = \"tusimple_processed/train/images\"\n",
    "test_image_folder = \"tusimple_processed/test/images\"\n",
    "train_mask_folder = \"tusimple_processed/train/masks\"\n",
    "test_mask_folder = \"tusimple_processed/test/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:38.756858Z",
     "iopub.status.busy": "2025-05-18T07:19:38.756616Z",
     "iopub.status.idle": "2025-05-18T07:19:38.772654Z",
     "shell.execute_reply": "2025-05-18T07:19:38.772015Z",
     "shell.execute_reply.started": "2025-05-18T07:19:38.756833Z"
    }
   },
   "outputs": [],
   "source": [
    "for folder_path in [train_image_folder, test_image_folder, train_mask_folder, test_mask_folder]:\n",
    "    create_dirs_if_not_exist(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(IMAGE_FOLDER) \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      3\u001b[0m masks \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(MASK_FOLDER) \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# split for train and test\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images = [file for file in os.listdir(IMAGE_FOLDER) if file.endswith(\".jpg\")]\n",
    "masks = [file for file in os.listdir(MASK_FOLDER) if file.endswith(\".jpg\")]\n",
    "\n",
    "# split for train and test\n",
    "lane_train_images, lane_test_images = train_test_split(images, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:39.195585Z",
     "iopub.status.busy": "2025-05-18T07:19:39.19508Z",
     "iopub.status.idle": "2025-05-18T07:19:39.200286Z",
     "shell.execute_reply": "2025-05-18T07:19:39.199672Z",
     "shell.execute_reply.started": "2025-05-18T07:19:39.195565Z"
    }
   },
   "outputs": [],
   "source": [
    "len(lane_train_images), len(lane_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:39.201162Z",
     "iopub.status.busy": "2025-05-18T07:19:39.200954Z",
     "iopub.status.idle": "2025-05-18T07:19:39.388917Z",
     "shell.execute_reply": "2025-05-18T07:19:39.388371Z",
     "shell.execute_reply.started": "2025-05-18T07:19:39.201141Z"
    }
   },
   "outputs": [],
   "source": [
    "# move files to the corresponding folders\n",
    "for file in lane_train_images:\n",
    "    # move the image and mask\n",
    "    source = os.path.join(IMAGE_FOLDER, file)\n",
    "    destination = os.path.join(train_image_folder, file)\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "    source = os.path.join(MASK_FOLDER, file)\n",
    "    destination = os.path.join(train_mask_folder, file)\n",
    "    shutil.move(source, destination)\n",
    "\n",
    "for file in lane_test_images:\n",
    "    # move the image and mask\n",
    "    source = os.path.join(IMAGE_FOLDER, file)\n",
    "    destination = os.path.join(test_image_folder, file)\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "    source = os.path.join(MASK_FOLDER, file)\n",
    "    destination = os.path.join(test_mask_folder, file)\n",
    "    shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:39.389743Z",
     "iopub.status.busy": "2025-05-18T07:19:39.389564Z",
     "iopub.status.idle": "2025-05-18T07:19:39.39605Z",
     "shell.execute_reply": "2025-05-18T07:19:39.39523Z",
     "shell.execute_reply.started": "2025-05-18T07:19:39.389728Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_image(image_path, mask_path):\n",
    "    size = [224, 224]\n",
    "    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, size)\n",
    "    image = image / 255.0  \n",
    "\n",
    "    \n",
    "    kernel = tf.constant([[0., -1., 0.],\n",
    "                          [-1., 5., -1.],\n",
    "                          [0., -1., 0.]], dtype=tf.float32)\n",
    "    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n",
    "    sharpened_channels = []\n",
    "    for c in channels:\n",
    "        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n",
    "        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n",
    "    image = tf.concat(sharpened_channels, axis=-1)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)  \n",
    "\n",
    "  \n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, size)\n",
    "    mask = mask / 255.0  \n",
    "    \n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:39.397465Z",
     "iopub.status.busy": "2025-05-18T07:19:39.396772Z",
     "iopub.status.idle": "2025-05-18T07:19:39.411346Z",
     "shell.execute_reply": "2025-05-18T07:19:39.410703Z",
     "shell.execute_reply.started": "2025-05-18T07:19:39.397441Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_from_folder(image_folder, mask_folder):\n",
    "    image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(\".jpg\")])\n",
    "    mask_files = sorted([os.path.join(mask_folder, file) for file in os.listdir(mask_folder) if file.endswith(\".jpg\")])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_files, mask_files))\n",
    "    dataset = dataset.map(lambda image_path, mask_path: load_image(image_path, mask_path))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:39.412167Z",
     "iopub.status.busy": "2025-05-18T07:19:39.411946Z",
     "iopub.status.idle": "2025-05-18T07:19:40.540243Z",
     "shell.execute_reply": "2025-05-18T07:19:40.539528Z",
     "shell.execute_reply.started": "2025-05-18T07:19:39.412152Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset from folder\n",
    "train_dataset = dataset_from_folder(train_image_folder, train_mask_folder)\n",
    "test_dataset = dataset_from_folder(test_image_folder, test_mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:40.541101Z",
     "iopub.status.busy": "2025-05-18T07:19:40.540924Z",
     "iopub.status.idle": "2025-05-18T07:19:40.565681Z",
     "shell.execute_reply": "2025-05-18T07:19:40.565154Z",
     "shell.execute_reply.started": "2025-05-18T07:19:40.541087Z"
    }
   },
   "outputs": [],
   "source": [
    "# set config\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "# optimize for performance improvement\n",
    "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_datset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:40.56885Z",
     "iopub.status.busy": "2025-05-18T07:19:40.568678Z",
     "iopub.status.idle": "2025-05-18T07:19:40.573169Z",
     "shell.execute_reply": "2025-05-18T07:19:40.572526Z",
     "shell.execute_reply.started": "2025-05-18T07:19:40.568837Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_sample(image_list):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    titles = [\"Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "        plt.subplot(1, len(image_list), i+1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:40.574263Z",
     "iopub.status.busy": "2025-05-18T07:19:40.573996Z",
     "iopub.status.idle": "2025-05-18T07:19:48.449406Z",
     "shell.execute_reply": "2025-05-18T07:19:48.448808Z",
     "shell.execute_reply.started": "2025-05-18T07:19:40.574246Z"
    }
   },
   "outputs": [],
   "source": [
    "for image, mask in train_dataset.take(1):\n",
    "    display_sample([image[0], mask[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation - VGG-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:48.450386Z",
     "iopub.status.busy": "2025-05-18T07:19:48.450124Z",
     "iopub.status.idle": "2025-05-18T07:19:54.120662Z",
     "shell.execute_reply": "2025-05-18T07:19:54.120098Z",
     "shell.execute_reply.started": "2025-05-18T07:19:48.450369Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, Dropout, Activation, Add, BatchNormalization, Conv2D, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def VGG16_UNet(input_shape=(None, None, 3)):\n",
    "    '''U net architechture with VGG16 encoder'''\n",
    "    def Conv2DReluBatchNorm(n_filters, kernel_size, stride, inputs):\n",
    "        x = Conv2D(n_filters, (1, 1), strides=1, \n",
    "                   padding=\"same\", kernel_initializer='glorot_normal', activation=\"elu\")(inputs)\n",
    "        x = Conv2D(n_filters, kernel_size, strides=stride, \n",
    "                   padding=\"same\", kernel_initializer='glorot_normal', activation=\"elu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.25)(x, training=True) # traininig + test-time ropout!\n",
    "        return x\n",
    "        \n",
    "    # VGG16 encoder\n",
    "    vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Unfreeze VGG16 layers\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Encoder layers\n",
    "    inputs = vgg16.input\n",
    "    layer1 = vgg16.get_layer(\"block1_conv2\").output\n",
    "    layer2 = vgg16.get_layer(\"block2_conv2\").output\n",
    "    layer3 = vgg16.get_layer(\"block3_conv3\").output\n",
    "    layer4 = vgg16.get_layer(\"block4_conv3\").output\n",
    "    layer5 = vgg16.get_layer(\"block5_conv3\").output\n",
    "\n",
    "    # Decoder layers\n",
    "    merge6 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer5), layer4])\n",
    "    layer6 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge6)\n",
    "\n",
    "    merge7 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer6), layer3])\n",
    "    layer7 = Conv2DReluBatchNorm(256, (3, 3), (1, 1), merge7)\n",
    "\n",
    "    merge8 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer7), layer2])\n",
    "    layer8 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge8)\n",
    "\n",
    "    merge9 = Concatenate(axis=-1)([UpSampling2D(size=(2, 2))(layer8), layer1])\n",
    "    layer9 = Conv2DReluBatchNorm(512, (3, 3), (1, 1), merge9)\n",
    "\n",
    "    output = Conv2D(1, (1, 1), strides=(1, 1), activation=\"sigmoid\", name=\"output\")(layer9)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model = VGG16_UNet(input_shape=(224, 224, 3)) # Adjust input shape as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:54.121654Z",
     "iopub.status.busy": "2025-05-18T07:19:54.121401Z",
     "iopub.status.idle": "2025-05-18T07:19:54.128688Z",
     "shell.execute_reply": "2025-05-18T07:19:54.128055Z",
     "shell.execute_reply.started": "2025-05-18T07:19:54.121633Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coefficent(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    mu = y_pred[:, :, :, 0]\n",
    "    y_pred_f = K.flatten(mu)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    smooth = 1.0\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficent(y_true, y_pred)\n",
    "\n",
    "def recall_smooth(y_true, y_pred):\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection / (K.sum(y_true_f) + K.epsilon()))\n",
    "\n",
    "def precision_smooth(y_true, y_pred):\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection / (K.sum(y_true_f) + K.epsilon()))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "\n",
    "    # True positives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true_f * y_pred_f, 0, 1)))\n",
    "    \n",
    "    # True negatives\n",
    "    true_negatives = K.sum(K.round(K.clip((1- y_true_f) * (1 - y_pred_f), 0, 1)))\n",
    "    \n",
    "    # Total pixels\n",
    "    total_pixels = K.cast(tensorflow.size(y_true_f), K.floatx())\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy_value = (true_positives + true_negatives) / total_pixels\n",
    "\n",
    "    return accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:54.129532Z",
     "iopub.status.busy": "2025-05-18T07:19:54.129318Z",
     "iopub.status.idle": "2025-05-18T07:19:54.153018Z",
     "shell.execute_reply": "2025-05-18T07:19:54.152495Z",
     "shell.execute_reply.started": "2025-05-18T07:19:54.129518Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=dice_loss, metrics=[dice_coefficent, precision_smooth, recall_smooth, accuracy])\n",
    "print(f'Number of parameters: {model.count_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:54.15383Z",
     "iopub.status.busy": "2025-05-18T07:19:54.153635Z",
     "iopub.status.idle": "2025-05-18T07:19:54.525778Z",
     "shell.execute_reply": "2025-05-18T07:19:54.525092Z",
     "shell.execute_reply.started": "2025-05-18T07:19:54.153809Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the model\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=False, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:54.527242Z",
     "iopub.status.busy": "2025-05-18T07:19:54.526755Z",
     "iopub.status.idle": "2025-05-18T07:19:54.532339Z",
     "shell.execute_reply": "2025-05-18T07:19:54.531574Z",
     "shell.execute_reply.started": "2025-05-18T07:19:54.527218Z"
    }
   },
   "outputs": [],
   "source": [
    "# create mask from prediction\n",
    "def create_mask(pred_mask):\n",
    "    # round to closest\n",
    "    pred_mask = tf.math.round(pred_mask)\n",
    "    return pred_mask\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for images, masks in dataset.take(num):\n",
    "            pred_mask = model.predict(images)\n",
    "            pred_mask = create_mask(pred_mask[0])\n",
    "            display_sample([images[0], masks[0], pred_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:19:54.533374Z",
     "iopub.status.busy": "2025-05-18T07:19:54.533104Z",
     "iopub.status.idle": "2025-05-18T07:20:42.532563Z",
     "shell.execute_reply": "2025-05-18T07:20:42.531996Z",
     "shell.execute_reply.started": "2025-05-18T07:19:54.53335Z"
    }
   },
   "outputs": [],
   "source": [
    "show_predictions(train_dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:20:42.533529Z",
     "iopub.status.busy": "2025-05-18T07:20:42.533311Z",
     "iopub.status.idle": "2025-05-18T07:20:42.540685Z",
     "shell.execute_reply": "2025-05-18T07:20:42.540087Z",
     "shell.execute_reply.started": "2025-05-18T07:20:42.533508Z"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks and logs\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, Callback\n",
    "import datetime\n",
    "\n",
    "class DisplayCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_predictions(test_dataset, 1)\n",
    "        print(f\"Sample Prediction after epoch {epoch}\\n\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "callbacks = [\n",
    "    DisplayCallback(), \n",
    "    TensorBoard(logdir, histogram_freq=-1),\n",
    "    EarlyStopping(patience=5, verbose=1),\n",
    "    ModelCheckpoint(\"best_model.keras\", verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:20:42.541501Z",
     "iopub.status.busy": "2025-05-18T07:20:42.541338Z",
     "iopub.status.idle": "2025-05-18T07:20:42.554561Z",
     "shell.execute_reply": "2025-05-18T07:20:42.553986Z",
     "shell.execute_reply.started": "2025-05-18T07:20:42.541488Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "steps_per_epoch = len(os.listdir(train_image_folder)) // BATCH_SIZE\n",
    "validation_steps = len(os.listdir(test_image_folder)) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T07:20:42.555417Z",
     "iopub.status.busy": "2025-05-18T07:20:42.555226Z",
     "iopub.status.idle": "2025-05-18T08:05:34.645343Z",
     "shell.execute_reply": "2025-05-18T08:05:34.644794Z",
     "shell.execute_reply.started": "2025-05-18T07:20:42.555403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:34.646445Z",
     "iopub.status.busy": "2025-05-18T08:05:34.646205Z",
     "iopub.status.idle": "2025-05-18T08:05:34.96851Z",
     "shell.execute_reply": "2025-05-18T08:05:34.967824Z",
     "shell.execute_reply.started": "2025-05-18T08:05:34.646428Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot train and val accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "\n",
    "# plot train and val loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_history.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:34.969933Z",
     "iopub.status.busy": "2025-05-18T08:05:34.969348Z",
     "iopub.status.idle": "2025-05-18T08:05:35.977453Z",
     "shell.execute_reply": "2025-05-18T08:05:35.976869Z",
     "shell.execute_reply.started": "2025-05-18T08:05:34.969896Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\n",
    "    \"best_model.keras\",\n",
    "    custom_objects={\n",
    "        \"dice_loss\": dice_loss,\n",
    "        \"dice_coefficent\": dice_coefficent,\n",
    "        \"precision_smooth\": precision_smooth,\n",
    "        \"recall_smooth\": recall_smooth,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    ")\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:35.978353Z",
     "iopub.status.busy": "2025-05-18T08:05:35.978124Z",
     "iopub.status.idle": "2025-05-18T08:05:43.690682Z",
     "shell.execute_reply": "2025-05-18T08:05:43.690017Z",
     "shell.execute_reply.started": "2025-05-18T08:05:35.978337Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "def save_prediction_plot(image_list, index=0, save_dir=\"prediction_plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    titles = [\"Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(image_list)):\n",
    "        plt.subplot(1, len(image_list), i + 1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(array_to_img(image_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    filepath = os.path.join(save_dir, f\"prediction_{index}.png\")\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"✅ Prediction plot saved: {filepath}\")\n",
    "\n",
    "def show_and_save_predictions(dataset=None, num=1, save_dir=\"prediction_plots\"):\n",
    "    if dataset:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        for i, (images, masks) in enumerate(dataset.take(num)):\n",
    "            pred_mask = model.predict(images)\n",
    "            pred_mask = create_mask(pred_mask[0])\n",
    "            display_sample([images[0], masks[0], pred_mask])\n",
    "            save_prediction_plot([images[0], masks[0], pred_mask], index=i, save_dir=save_dir)\n",
    "\n",
    "show_and_save_predictions(test_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test from Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:43.691899Z",
     "iopub.status.busy": "2025-05-18T08:05:43.691696Z",
     "iopub.status.idle": "2025-05-18T08:05:43.696022Z",
     "shell.execute_reply": "2025-05-18T08:05:43.69536Z",
     "shell.execute_reply.started": "2025-05-18T08:05:43.691883Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_test_image(image_path):\n",
    "    size = [224, 224]\n",
    "    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, size)\n",
    "    image = image / 255.0 # normalize to [0, 1]\n",
    "\n",
    "    kernel = tf.constant([[0., -1., 0.],\n",
    "                          [-1., 5., -1.],\n",
    "                          [0., -1., 0.]], dtype=tf.float32)\n",
    "    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n",
    "    sharpened_channels = []\n",
    "    for c in channels:\n",
    "        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n",
    "        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n",
    "    image = tf.concat(sharpened_channels, axis=-1)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)  \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:43.697052Z",
     "iopub.status.busy": "2025-05-18T08:05:43.696747Z",
     "iopub.status.idle": "2025-05-18T08:05:43.707842Z",
     "shell.execute_reply": "2025-05-18T08:05:43.70733Z",
     "shell.execute_reply.started": "2025-05-18T08:05:43.697027Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_test_sample(image_list):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    titles = [\"Image\", \"Predicted Mask\"]\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "        plt.subplot(1, len(image_list), i+1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:05:43.708569Z",
     "iopub.status.busy": "2025-05-18T08:05:43.708403Z",
     "iopub.status.idle": "2025-05-18T08:05:49.082093Z",
     "shell.execute_reply": "2025-05-18T08:05:49.081334Z",
     "shell.execute_reply.started": "2025-05-18T08:05:43.708549Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/tusimple/TUSimple/train_set/clips/0313-1/10000/20.jpg\"\n",
    "image = load_test_image(image_path)\n",
    "test_image = tf.expand_dims(image, axis=0)\n",
    "pred_mask = model.predict([test_image])\n",
    "pred_mask = create_mask(pred_mask[0])\n",
    "\n",
    "display_test_sample([image, pred_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Image Sequence to Video Using Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_frame(image_path):\n",
    "    size = [224, 224]\n",
    "    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, size)\n",
    "    image = image / 255.0  # normalize to [0, 1]\n",
    "\n",
    "    kernel = tf.constant([[0., -1., 0.],\n",
    "                          [-1., 5., -1.],\n",
    "                          [0., -1., 0.]], dtype=tf.float32)\n",
    "    kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "    channels = tf.split(image, num_or_size_splits=3, axis=-1)\n",
    "    sharpened_channels = []\n",
    "    for c in channels:\n",
    "        c_sharp = tf.nn.conv2d(tf.expand_dims(c, axis=0), kernel, strides=1, padding=\"SAME\")\n",
    "        sharpened_channels.append(tf.squeeze(c_sharp, axis=0))\n",
    "    image = tf.concat(sharpened_channels, axis=-1)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)  \n",
    "    \n",
    "    # Add batch dimension\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.round(pred_mask)\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_mask(pred_mask, original_frame):\n",
    "    pred_mask = pred_mask.numpy()\n",
    "    pred_mask = pred_mask[0, :, :, 0] if pred_mask.ndim == 4 else pred_mask[0]\n",
    "    pred_mask = (pred_mask * 255).astype(np.uint8)\n",
    "    pred_mask = cv2.resize(pred_mask, (original_frame.shape[1], original_frame.shape[0]))\n",
    "\n",
    "    # Create a blank image for the colored mask\n",
    "    mask_colored = np.zeros_like(original_frame)\n",
    "\n",
    "    # Yellow lane color (BGR): (0, 255, 255)\n",
    "    mask_colored[pred_mask > 0] = [0, 255, 255]\n",
    "\n",
    "    # Blend the original frame with the mask\n",
    "    blended = cv2.addWeighted(original_frame, 1.0, mask_colored, 0.6, 0)\n",
    "\n",
    "    return blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Input and output paths\n",
    "path = \"/kaggle/input/tusimple/TUSimple/test_set/clips/0530/1492626265087865031_0\"\n",
    "out_path = \"imgToVid\"\n",
    "out_video_name = \"driving_car_lanes.mp4\"\n",
    "out_video_full_path = os.path.join(out_path, out_video_name)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Load the Keras lane detection model (replace with your model path)\n",
    "model = load_model('best_model.keras', custom_objects={\n",
    "        \"dice_loss\": dice_loss,\n",
    "        \"dice_coefficent\": dice_coefficent,\n",
    "        \"precision_smooth\": precision_smooth,\n",
    "        \"recall_smooth\": recall_smooth,\n",
    "        \"accuracy\": accuracy\n",
    "    })  # Update with your model path\n",
    "\n",
    "# Get list of images and sort them\n",
    "pre_imgs = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "pre_imgs.sort()\n",
    "\n",
    "# Full paths to images\n",
    "img_paths = [os.path.join(path, i) for i in pre_imgs]\n",
    "\n",
    "# Read the first image to get size\n",
    "frame = cv2.imread(img_paths[0])\n",
    "if frame is None:\n",
    "    raise ValueError(f\"Failed to read first image: {img_paths[0]}\")\n",
    "\n",
    "height, width = frame.shape[:2]\n",
    "cv2_fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 12\n",
    "video = cv2.VideoWriter(out_video_full_path, cv2_fourcc, fps, (width, height))\n",
    "\n",
    "# Process each frame\n",
    "for img_path in img_paths:\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None:\n",
    "        print(f\"Warning: Could not read image {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    input_frame = load_and_preprocess_frame(img_path)\n",
    "    \n",
    "    pred_mask = model.predict(input_frame, verbose=0)\n",
    "    pred_mask = create_mask(pred_mask)\n",
    "    \n",
    "    output_frame = postprocess_mask(pred_mask, frame)\n",
    "    \n",
    "    video.write(output_frame)\n",
    "\n",
    "video.release()\n",
    "print(\"Video with masked lane predictions saved to:\", out_video_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:18:17.893316Z",
     "iopub.status.busy": "2025-05-18T08:18:17.893017Z",
     "iopub.status.idle": "2025-05-18T08:18:17.928193Z",
     "shell.execute_reply": "2025-05-18T08:18:17.927376Z",
     "shell.execute_reply.started": "2025-05-18T08:18:17.893297Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def play(filename):\n",
    "    html = ''\n",
    "    video = open(filename,'rb').read()\n",
    "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
    "    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n",
    "    return HTML(html)\n",
    "\n",
    "play(out_video_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging Model, Training Metrics, and Output Video into a ZIP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"training_history.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header\n",
    "    writer.writerow([\"Epoch\", \"Train_Loss\", \"Train_Accuracy\", \"Val_Loss\", \"Val_Accuracy\"])\n",
    "    \n",
    "    # Write data\n",
    "    for epoch in range(len(history.history['loss'])):\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            history.history['loss'][epoch],\n",
    "            history.history['accuracy'][epoch],\n",
    "            history.history['val_loss'][epoch],\n",
    "            history.history['val_accuracy'][epoch]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "import os\n",
    "\n",
    "files = [\n",
    "    \"training_history.csv\",\n",
    "    \"training_history.svg\",\n",
    "    \"best_model.keras\",\n",
    "    \"imgToVid/driving_car_lanes.mp4\"\n",
    "]\n",
    "\n",
    "plots_dir = \"prediction_plots\"\n",
    "\n",
    "zip_filename = \"model_and_metrics.zip\"\n",
    "\n",
    "def add_file_to_zip(file_name, zipf):\n",
    "    zipf.write(file_name)\n",
    "    print(f\"✅ Added to zip: {file_name}\")\n",
    "\n",
    "def add_folder_to_zip(directory, zipf):\n",
    "    for foldername, subfolders, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "           \n",
    "            arcname = os.path.relpath(filepath, start=os.path.dirname(directory))\n",
    "            zipf.write(filepath, arcname=arcname)\n",
    "        print(f\"✅ Added to zip: {foldername}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    for file in files:\n",
    "        add_file_to_zip(file, zipf)\n",
    "\n",
    "    add_folder_to_zip(plots_dir, zipf)\n",
    "\n",
    "print(f\"✅ Zip created: {zip_filename} (includes model, metrics CSV, video, and prediction plots)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, display, HTML\n",
    "\n",
    "# Create and display download link\n",
    "display(FileLink(zip_filename))\n",
    "\n",
    "display(HTML(\"<h3 style='color:red;'>⚠️ Don't forget to click and download the zip file before closing the session!</h3>\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1724942,
     "sourceId": 2840219,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 345458,
     "modelInstanceId": 324647,
     "sourceId": 395008,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "custom_python_kernel",
   "language": "python",
   "name": "custom_python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
