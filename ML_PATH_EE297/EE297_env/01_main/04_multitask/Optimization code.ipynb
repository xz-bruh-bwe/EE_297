{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dde7da-8806-4fff-9616-9c8400197e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST!! USE FOR OPTIMIZATION LATER\n",
    "# yolo_with_seg.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "from utils.general import non_max_suppression, scale_boxes\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# YOLO-style letterbox (with Â±0.1 rounding)\n",
    "# ----------------------------\n",
    "def _letterbox(im, new_shape=640, color=(114, 114, 114),\n",
    "               auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    \"\"\"\n",
    "    Resize and pad image to meet stride-multiple constraints.\n",
    "    Returns (img, (r,r), (dw,dh)) where dw/dh are HALF paddings.\n",
    "    \"\"\"\n",
    "    h, w = im.shape[:2]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    r = min(new_shape[0] / h, new_shape[1] / w)  # scale ratio\n",
    "    if not scaleup:\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    new_unpad = (int(round(w * r)), int(round(h * r)))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # remaining wh\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        r = (new_shape[1] / w, new_shape[0] / h)\n",
    "\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    if (w, h) != new_unpad:\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return im, (r, r), (dw, dh)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Segmentation head (simple FPN)\n",
    "# ----------------------------\n",
    "class PyramidSegHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Inputs: feats [P3, P4, P5] (largest->smallest), out_hw=(H, W)\n",
    "    Output: logits B x out_ch x H x W\n",
    "    \"\"\"\n",
    "    def __init__(self, out_ch=1, fuse_ch=128):\n",
    "        super().__init__()\n",
    "        self.l3 = nn.LazyConv2d(fuse_ch, 1)  # for P5\n",
    "        self.l2 = nn.LazyConv2d(fuse_ch, 1)  # for P4\n",
    "        self.l1 = nn.LazyConv2d(fuse_ch, 1)  # for P3\n",
    "        self.s4 = nn.Conv2d(fuse_ch, fuse_ch, 3, padding=1)\n",
    "        self.s3 = nn.Conv2d(fuse_ch, fuse_ch, 3, padding=1)\n",
    "        self.o1 = nn.Conv2d(fuse_ch, 64, 3, padding=1)\n",
    "        self.o2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.logits = nn.Conv2d(32, out_ch, 1)\n",
    "\n",
    "    def forward(self, feats: List[torch.Tensor], out_hw: Tuple[int, int]):\n",
    "        p3, p4, p5 = feats\n",
    "        t5 = self.l3(p5)\n",
    "        t4 = self.l2(p4) + F.interpolate(t5, size=p4.shape[-2:], mode=\"nearest\")\n",
    "        t4 = F.relu(self.s4(t4), inplace=True)\n",
    "        t3 = self.l1(p3) + F.interpolate(t4, size=p3.shape[-2:], mode=\"nearest\")\n",
    "        t3 = F.relu(self.s3(t3), inplace=True)\n",
    "        x = F.relu(self.o1(t3), inplace=True)\n",
    "        x = F.relu(self.o2(x), inplace=True)\n",
    "        x = self.logits(x)\n",
    "        x = F.interpolate(x, size=out_hw, mode=\"bilinear\", align_corners=False)\n",
    "        return x  # logits\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Shared encoder multitask model\n",
    "# ----------------------------\n",
    "class YoloV5WithSeg(nn.Module):\n",
    "    \"\"\"\n",
    "    ONE model: YOLO backbone+neck+Detect (shared) + a segmentation head.\n",
    "\n",
    "    Training:\n",
    "        forward(images_01: torch.Tensor[B,3,H,W]) -> (pred_raw, seg_logits)\n",
    "        - seg_logits are *logits*; use BCEWithLogitsLoss or similar.\n",
    "\n",
    "    Inference:\n",
    "        detect(path_or_np, size=640) -> (det_xyxy[N,6], seg_prob[H,W])\n",
    "        - det boxes are mapped back to original image size\n",
    "        - seg_prob is a probability map in original image size\n",
    "    \"\"\"\n",
    "    def __init__(self, yolo_variant=\"yolov5s\", pretrained=True,\n",
    "                 seg_out_ch=1, fuse_ch=128,\n",
    "                 conf=0.25, iou=0.45, max_det=300, agnostic=False):\n",
    "        super().__init__()\n",
    "        yolo = torch.hub.load(\"ultralytics/yolov5\", yolo_variant, pretrained=pretrained)\n",
    "        if hasattr(yolo, \"model\"):  # unwrap AutoShape\n",
    "            yolo = yolo.model\n",
    "\n",
    "        self.yolo = yolo\n",
    "        self.yolo.conf = conf\n",
    "        self.yolo.iou = iou\n",
    "        self.yolo.max_det = max_det\n",
    "        self.yolo.agnostic = agnostic\n",
    "        self.stride = int(getattr(self.yolo, \"stride\", 32))\n",
    "        self.yolo.eval()\n",
    "\n",
    "        # class names (safe)\n",
    "        raw_names = getattr(self.yolo, \"names\", None)\n",
    "        if isinstance(raw_names, dict):\n",
    "            self.names = [raw_names[i] for i in range(len(raw_names))]\n",
    "        elif isinstance(raw_names, (list, tuple)):\n",
    "            self.names = list(raw_names)\n",
    "        else:\n",
    "            self.names = []\n",
    "\n",
    "        # find Detect head\n",
    "        self.detect_head = None\n",
    "        for m in self.yolo.modules():\n",
    "            if m.__class__.__name__ == \"Detect\":\n",
    "                self.detect_head = m\n",
    "                break\n",
    "        if self.detect_head is None:\n",
    "            raise RuntimeError(\"Couldn't find YOLOv5 Detect module.\")\n",
    "\n",
    "        # segmentation head\n",
    "        self.seg_head = PyramidSegHead(out_ch=seg_out_ch, fuse_ch=fuse_ch)\n",
    "\n",
    "    # ----- collect outputs -----\n",
    "    def _forward_collect(self, x: torch.Tensor):\n",
    "        cache = []\n",
    "        z = x\n",
    "        p3 = p4 = p5 = None\n",
    "        pred_raw = None\n",
    "\n",
    "        seq = getattr(self.yolo, \"model\", None)\n",
    "        seq = getattr(seq, \"model\", None) if hasattr(seq, \"model\") else seq\n",
    "        if seq is None:\n",
    "            raise RuntimeError(\"Unexpected YOLO structure\")\n",
    "\n",
    "        for m in seq:\n",
    "            f = getattr(m, 'f', -1)\n",
    "            if f == -1:\n",
    "                u = z\n",
    "            elif isinstance(f, int):\n",
    "                u = cache[f]\n",
    "            else:\n",
    "                u = [z if j == -1 else cache[j] for j in f]\n",
    "\n",
    "            z = m(u)\n",
    "            cache.append(z)\n",
    "\n",
    "            if m is self.detect_head:\n",
    "                pred_raw = z\n",
    "                f_list = getattr(self.detect_head, 'f', [])\n",
    "                if isinstance(f_list, (list, tuple)) and len(f_list) >= 3:\n",
    "                    p3, p4, p5 = [cache[j] for j in f_list[-3:]]\n",
    "                elif isinstance(u, (list, tuple)) and len(u) >= 3:\n",
    "                    p3, p4, p5 = u[-3:]\n",
    "\n",
    "        if pred_raw is None or p3 is None:\n",
    "            raise RuntimeError(\"Failed to obtain Detect outputs or P3/P4/P5.\")\n",
    "        return pred_raw, [p3, p4, p5]\n",
    "\n",
    "    # ----- training path -----\n",
    "    def forward(self, images_01: torch.Tensor):\n",
    "        pred_raw, feats = self._forward_collect(images_01)\n",
    "        B, _, H, W = images_01.shape\n",
    "        seg_logits = self.seg_head(feats, out_hw=(H, W))\n",
    "        return pred_raw, seg_logits\n",
    "\n",
    "    # ----- eval convenience -----\n",
    "    @torch.inference_mode()\n",
    "    def detect(self, img_path_or_np, size=640, device: Optional[torch.device] = None, return_logits=False):\n",
    "        dev = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(dev)\n",
    "\n",
    "        # Force eval for consistent Detect behavior, then restore flags\n",
    "        was_training_self = self.training\n",
    "        was_training_yolo = self.yolo.training\n",
    "        self.eval()\n",
    "        self.yolo.eval()\n",
    "\n",
    "        try:\n",
    "            # load image\n",
    "            if isinstance(img_path_or_np, str):\n",
    "                im0 = cv2.imread(img_path_or_np)\n",
    "                if im0 is None:\n",
    "                    raise FileNotFoundError(img_path_or_np)\n",
    "                im0 = im0[:, :, ::-1]  # BGR->RGB\n",
    "            else:\n",
    "                im0 = img_path_or_np\n",
    "            H0, W0 = im0.shape[:2]\n",
    "\n",
    "            # letterbox\n",
    "            lb, _, (dw, dh) = _letterbox(im0, new_shape=size, stride=self.stride)\n",
    "            im = torch.from_numpy(np.ascontiguousarray(lb.transpose(2, 0, 1))).float() / 255.0\n",
    "            im = im.unsqueeze(0).to(dev)\n",
    "\n",
    "            # forward\n",
    "            pred_raw, feats = self._forward_collect(im)\n",
    "\n",
    "            # normalize Detect output to [B, N, 5+nc]\n",
    "            if isinstance(pred_raw, dict) and \"pred\" in pred_raw:\n",
    "                pred = pred_raw[\"pred\"]\n",
    "            elif isinstance(pred_raw, (list, tuple)):\n",
    "                if len(pred_raw) == 1 and pred_raw[0].ndim == 3:\n",
    "                    pred = pred_raw[0]\n",
    "                else:\n",
    "                    shapes = [getattr(p, \"shape\", None) for p in pred_raw]\n",
    "                    raise RuntimeError(f\"Unexpected Detect output in eval(): {shapes}\")\n",
    "            else:\n",
    "                pred = pred_raw\n",
    "\n",
    "            if pred.ndim == 2:\n",
    "                pred = pred.unsqueeze(0)\n",
    "\n",
    "            # NMS\n",
    "            nms_out = non_max_suppression(\n",
    "                pred,\n",
    "                conf_thres=self.yolo.conf,\n",
    "                iou_thres=self.yolo.iou,\n",
    "                classes=None,\n",
    "                agnostic=self.yolo.agnostic,\n",
    "                max_det=self.yolo.max_det\n",
    "            )\n",
    "            det = nms_out[0]\n",
    "            if det is None or len(det) == 0:\n",
    "                det_xyxy = torch.empty((0, 6), device=im.device)\n",
    "            else:\n",
    "                det_xyxy = det.clone()\n",
    "                det_xyxy[:, :4] = scale_boxes(im.shape[2:], det_xyxy[:, :4], im0.shape).round()\n",
    "\n",
    "            # segmentation (predict at letterboxed size, crop padding, then resize to original)\n",
    "            Hlb, Wlb = im.shape[2], im.shape[3]\n",
    "            seg_logits = self.seg_head(feats, out_hw=(Hlb, Wlb))\n",
    "\n",
    "            left  = int(round(float(dw) - 0.1))\n",
    "            right = int(round(float(dw) + 0.1))\n",
    "            top   = int(round(float(dh) - 0.1))\n",
    "            bot   = int(round(float(dh) + 0.1))\n",
    "\n",
    "            seg_logits = seg_logits[..., top:Hlb - bot, left:Wlb - right]\n",
    "            seg_logits = F.interpolate(seg_logits, size=(H0, W0), mode='bilinear', align_corners=False)\n",
    "\n",
    "            seg = seg_logits[0, 0]\n",
    "            if not return_logits:\n",
    "                seg = torch.sigmoid(seg)\n",
    "\n",
    "            return det_xyxy, seg\n",
    "\n",
    "        finally:\n",
    "            # restore train/eval flags\n",
    "            if was_training_self:\n",
    "                self.train()\n",
    "            if was_training_yolo:\n",
    "                self.yolo.train()\n",
    "\n",
    "    # ----- freeze helpers -----\n",
    "    def freeze_backbone(self, freeze: bool = True):\n",
    "        \"\"\"Freeze/unfreeze all YOLO backbone+neck layers (everything except Detect + seg head).\"\"\"\n",
    "        for p in self.yolo.parameters():\n",
    "            p.requires_grad = not freeze\n",
    "\n",
    "    def freeze_detect(self, freeze: bool = True):\n",
    "        \"\"\"Freeze/unfreeze the YOLO Detect head only.\"\"\"\n",
    "        if self.detect_head is not None:\n",
    "            for p in self.detect_head.parameters():\n",
    "                p.requires_grad = not freeze\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
