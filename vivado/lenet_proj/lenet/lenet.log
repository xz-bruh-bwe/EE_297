==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.c' ... 
ERROR: [HLS 207-814] "AP data type can only be used in C++": Z:/Vitis/2020.1/common/technology/autopilot\ap_decl.h:93:2
ERROR: [HLS 207-814] "C++ is required to include this header file": Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:62:2
ERROR: [HLS 207-814] "C++ is required to include this header file": Z:/Vitis/2020.1/common/technology/autopilot\ap_int_ref.h:62:2
ERROR: [HLS 207-814] "C++ is required to include this header file": Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:71:2
ERROR: [HLS 207-814] "C++ is required to include this header file": Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_ref.h:62:2
ERROR: [HLS 207-814] C++ is required to include this header file: Z:/Vitis/2020.1/common/technology/autopilot/hls_stream_39.h:63:2
ERROR: [HLS 207-812] 'conv1_weights.h' file not found: lenet_proj/lenet_top.c:4:10
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Cannot find source file lenet_proj/lenet_top.c; skipping it.
ERROR: [HLS 200-70] Cannot find any design unit to elaborate.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-812] 'conv1_weights.h' file not found: lenet_proj/lenet_top.cpp:4:10
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:27:22)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_28_2' (lenet_proj/lenet_top.cpp:28) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_36_5' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_39_6' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_40_7' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_top.cpp:24:37)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_27_1' (lenet_proj/lenet_top.cpp:27:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_35_4' (lenet_proj/lenet_top.cpp:35:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_34_3' (lenet_proj/lenet_top.cpp:34:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded' (lenet_proj/lenet_top.cpp:29:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:16 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln47) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln47_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_27_1_VITIS_LOOP_28_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_34_3_VITIS_LOOP_35_4_VITIS_LOOP_36_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_load_2', lenet_proj/lenet_top.cpp:41) on array 'padded', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 89.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 16.458 seconds; current allocated memory: 150.309 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.441 seconds; current allocated memory: 152.036 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.404 seconds; current allocated memory: 152.198 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.146 seconds; current allocated memory: 152.387 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.494 seconds; current allocated memory: 155.551 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.531 seconds; current allocated memory: 160.961 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:12 ; elapsed = 00:00:28 . Memory (MB): peak = 997.766 ; gain = 900.117
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 127.59 MHz
INFO: [HLS 200-112] Total elapsed time: 28.503 seconds; peak allocated memory: 160.961 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:44:38) in function 'conv2d_layer' completely with a factor of 5 (lenet_proj/lenet_top.cpp:44:38)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:30:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:05 ; elapsed = 00:00:14 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:05 ; elapsed = 00:00:15 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:05 ; elapsed = 00:00:15 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:05 ; elapsed = 00:00:15 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_31_2' (lenet_proj/lenet_top.cpp:31) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_38_4' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 28.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 completely.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:16 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_30_1' (lenet_proj/lenet_top.cpp:30:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_37_3' (lenet_proj/lenet_top.cpp:37:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[8]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[9]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[10]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[11]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[12]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[13]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[14]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[15]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[16]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[17]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[18]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[19]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[20]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[21]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[22]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[23]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[24]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[25]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[26]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[27]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[28]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[29]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' (lenet_proj/lenet_top.cpp:32:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:19 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_30_1_VITIS_LOOP_31_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_37_3_VITIS_LOOP_38_4'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_2_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[2]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_2'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_top.cpp:52) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 28, Depth = 172.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 243.207 seconds; current allocated memory: 174.424 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.701 seconds; current allocated memory: 188.008 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 3.003 seconds; current allocated memory: 189.550 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.317 seconds; current allocated memory: 189.754 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 26 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 25 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 2.033 seconds; current allocated memory: 203.853 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 10.799 seconds; current allocated memory: 238.641 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_2_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:04:11 ; elapsed = 00:04:32 . Memory (MB): peak = 997.625 ; gain = 899.859
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 120.78 MHz
INFO: [HLS 200-112] Total elapsed time: 272.397 seconds; peak allocated memory: 238.641 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:30:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_31_2' (lenet_proj/lenet_top.cpp:31) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_38_4' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 28.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 completely.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_30_1' (lenet_proj/lenet_top.cpp:30:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_37_3' (lenet_proj/lenet_top.cpp:37:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[8]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[9]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[10]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[11]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[12]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[13]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[14]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[15]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[16]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[17]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[18]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[19]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[20]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[21]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[22]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[23]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[24]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[25]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[26]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[27]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[28]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[29]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' (lenet_proj/lenet_top.cpp:32:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:19 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_30_1_VITIS_LOOP_31_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_37_3_VITIS_LOOP_38_4'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_2_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[2]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_2'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_top.cpp:52) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 28, Depth = 172.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 242.566 seconds; current allocated memory: 174.492 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.672 seconds; current allocated memory: 188.077 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 3.022 seconds; current allocated memory: 189.603 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.306 seconds; current allocated memory: 189.807 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 26 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 25 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.946 seconds; current allocated memory: 203.922 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 10.837 seconds; current allocated memory: 238.805 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_2_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:04:10 ; elapsed = 00:04:32 . Memory (MB): peak = 998.418 ; gain = 900.723
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 120.78 MHz
INFO: [HLS 200-112] Total elapsed time: 271.748 seconds; peak allocated memory: 238.805 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:30:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_31_2' (lenet_proj/lenet_top.cpp:31) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_38_4' (lenet_proj/lenet_top.cpp:38) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 28.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3]' in function 'conv2d_layer'.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_30_1' (lenet_proj/lenet_top.cpp:30:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_37_3' (lenet_proj/lenet_top.cpp:37:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' (lenet_proj/lenet_top.cpp:32:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:18 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_30_1_VITIS_LOOP_31_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_37_3_VITIS_LOOP_38_4'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_top.cpp:52) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 28, Depth = 172.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 33.012 seconds; current allocated memory: 172.763 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.554 seconds; current allocated memory: 185.288 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.95 seconds; current allocated memory: 186.838 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.297 seconds; current allocated memory: 187.043 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 26 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 25 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.853 seconds; current allocated memory: 200.778 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 10.814 seconds; current allocated memory: 235.086 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:41 ; elapsed = 00:01:02 . Memory (MB): peak = 998.047 ; gain = 900.316
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 120.78 MHz
INFO: [HLS 200-112] Total elapsed time: 61.747 seconds; peak allocated memory: 235.086 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:60:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:30:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_31_2' (lenet_proj/lenet_top.cpp:31) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_39_5' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_39_5' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_42_6' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_7' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:59)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_30_1' (lenet_proj/lenet_top.cpp:30:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_4' (lenet_proj/lenet_top.cpp:38:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_37_3' (lenet_proj/lenet_top.cpp:37:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' (lenet_proj/lenet_top.cpp:32:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln51) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln51_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_30_1_VITIS_LOOP_31_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_37_3_VITIS_LOOP_38_4_VITIS_LOOP_39_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_load_2', lenet_proj/lenet_top.cpp:45) on array 'padded[0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 90.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 17.093 seconds; current allocated memory: 142.913 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.596 seconds; current allocated memory: 145.478 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_464_32_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.035 seconds; current allocated memory: 149.889 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:14 ; elapsed = 00:00:30 . Memory (MB): peak = 998.227 ; gain = 900.551
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 127.59 MHz
INFO: [HLS 200-112] Total elapsed time: 30.393 seconds; peak allocated memory: 149.889 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:60:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:30:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_31_2' (lenet_proj/lenet_top.cpp:31) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_39_5' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_39_5' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_42_6' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_7' (lenet_proj/lenet_top.cpp:41) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:59)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_30_1' (lenet_proj/lenet_top.cpp:30:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_4' (lenet_proj/lenet_top.cpp:38:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_37_3' (lenet_proj/lenet_top.cpp:37:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0]' (lenet_proj/lenet_top.cpp:32:34)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln51) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln51_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_30_1_VITIS_LOOP_31_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_37_3_VITIS_LOOP_38_4_VITIS_LOOP_39_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_load_2', lenet_proj/lenet_top.cpp:45) on array 'padded[0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 90.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 16.984 seconds; current allocated memory: 142.913 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.609 seconds; current allocated memory: 145.478 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_464_32_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.035 seconds; current allocated memory: 149.889 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:14 ; elapsed = 00:00:29 . Memory (MB): peak = 997.941 ; gain = 900.277
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 127.59 MHz
INFO: [HLS 200-112] Total elapsed time: 29.147 seconds; peak allocated memory: 149.889 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:19 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 90.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 22.931 seconds; current allocated memory: 151.631 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.135 seconds; current allocated memory: 157.037 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.745 seconds; current allocated memory: 164.949 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:21 ; elapsed = 00:00:38 . Memory (MB): peak = 997.953 ; gain = 900.273
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 127.59 MHz
INFO: [HLS 200-112] Total elapsed time: 38.621 seconds; peak allocated memory: 164.949 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.742 ; gain = 900.039
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.742 ; gain = 900.039
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.742 ; gain = 900.039
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.742 ; gain = 900.039
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'lenet_top' (lenet_proj/lenet_top.cpp:60).
INFO: [HLS 200-489] Unrolling loop 'Loop-1' in function 'lenet_top' completely with a factor of 1024.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31) in function 'lenet_top' completely with a factor of 28.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' completely with a factor of 28.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38) in function 'lenet_top' completely with a factor of 6.
ERROR: [HLS 200-1471] Stop unrolling loop 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38) in function 'lenet_top' because it may cause large runtime and excessive memory usage due to increase in code size. Please avoid unrolling the loop or form sub-functions for code in the loop body.\

ERROR: [HLS 200-70] Pre-synthesis failed.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7'.
WARNING: [HLS 200-40] Cannot find library 'Z:/Vitis/2020.1/common/technology/xilinx/Virtex-7/Virtex-7_fpv7.lib'.
WARNING: [HLS 200-40] Cannot find library 'xilinx/Virtex-7/Virtex-7_fpv7'.
INFO: [HLS 200-10] Setting target device to 'xcvu11p-flga2577-1-e'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:17 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:20 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 90.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 24.063 seconds; current allocated memory: 151.631 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.19 seconds; current allocated memory: 157.037 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_3_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_2_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.74 seconds; current allocated memory: 164.933 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:21 ; elapsed = 00:00:40 . Memory (MB): peak = 997.750 ; gain = 899.941
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 127.59 MHz
INFO: [HLS 200-112] Total elapsed time: 40.315 seconds; peak allocated memory: 164.933 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.5ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.5ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:15 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:16 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:19 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 144.
WARNING: [HLS 200-871] Estimated clock period (13.6915ns) exceeds the target (target clock period: 12.5ns, clock uncertainty: 3.375ns, effective delay budget: 9.125ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'add' operation ('add_ln31', lenet_proj/lenet_top.cpp:31) [195]  (1.78 ns)
	'select' operation ('select_ln31_2', lenet_proj/lenet_top.cpp:31) [203]  (1.22 ns)
	'add' operation ('add_ln31_2', lenet_proj/lenet_top.cpp:31) [205]  (1.65 ns)
	'getelementptr' operation ('padded_1_0_addr_1', lenet_proj/lenet_top.cpp:33) [219]  (0 ns)
	'store' operation ('padded_1_0_addr_1_write_ln33', lenet_proj/lenet_top.cpp:33) of variable 'gmem_addr_read', lenet_proj/lenet_top.cpp:33 on array 'padded[1][0]', lenet_proj/lenet_top.cpp:24 [257]  (3.25 ns)
	blocking operation 5.79 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 27.055 seconds; current allocated memory: 151.733 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.253 seconds; current allocated memory: 157.570 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.944 seconds; current allocated memory: 165.882 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:43 . Memory (MB): peak = 997.598 ; gain = 899.887
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 73.04 MHz
INFO: [HLS 200-112] Total elapsed time: 43.561 seconds; peak allocated memory: 165.882 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:18 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 145.
WARNING: [HLS 200-871] Estimated clock period (9.04625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 2.7ns, effective delay budget: 7.3ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'phi' operation ('empty') with incoming values : ('empty_24') [84]  (0 ns)
	'getelementptr' operation ('padded_2_2_addr') [107]  (0 ns)
	'store' operation ('padded_2_2_addr_write_ln0') of constant 0 on array 'padded[2][2]', lenet_proj/lenet_top.cpp:24 [117]  (3.25 ns)
	blocking operation 5.79 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 27.284 seconds; current allocated memory: 151.719 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.312 seconds; current allocated memory: 157.618 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.867 seconds; current allocated memory: 165.947 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:43 . Memory (MB): peak = 997.164 ; gain = 899.383
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 110.54 MHz
INFO: [HLS 200-112] Total elapsed time: 43.122 seconds; peak allocated memory: 165.947 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 8ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 8ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:18 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 224.
WARNING: [HLS 200-871] Estimated clock period (9.04625ns) exceeds the target (target clock period: 8ns, clock uncertainty: 2.16ns, effective delay budget: 5.84ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'phi' operation ('empty') with incoming values : ('empty_24') [84]  (0 ns)
	'getelementptr' operation ('padded_1_0_addr') [101]  (0 ns)
	'store' operation ('padded_1_0_addr_write_ln0') of constant 0 on array 'padded[1][0]', lenet_proj/lenet_top.cpp:24 [139]  (3.25 ns)
	blocking operation 5.79 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 26.89 seconds; current allocated memory: 151.902 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.372 seconds; current allocated memory: 158.334 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_8_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 2.014 seconds; current allocated memory: 167.165 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:43 . Memory (MB): peak = 997.324 ; gain = 899.652
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 110.54 MHz
INFO: [HLS 200-112] Total elapsed time: 43.641 seconds; peak allocated memory: 167.165 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:61:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:31:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_32_2' (lenet_proj/lenet_top.cpp:32) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_40_5' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_43_6' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_7' (lenet_proj/lenet_top.cpp:42) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:60)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_31_1' (lenet_proj/lenet_top.cpp:31:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_4' (lenet_proj/lenet_top.cpp:39:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_38_3' (lenet_proj/lenet_top.cpp:38:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:33:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:18 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln52_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_31_1_VITIS_LOOP_32_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_38_3_VITIS_LOOP_39_4_VITIS_LOOP_40_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_2', lenet_proj/lenet_top.cpp:46) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 13, Depth = 145.
WARNING: [HLS 200-871] Estimated clock period (9.04625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 2.7ns, effective delay budget: 7.3ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'phi' operation ('empty') with incoming values : ('empty_24') [84]  (0 ns)
	'getelementptr' operation ('padded_0_0_addr') [97]  (0 ns)
	'store' operation ('padded_0_0_addr_write_ln0') of constant 0 on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 [155]  (3.25 ns)
	blocking operation 5.79 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 26.931 seconds; current allocated memory: 151.719 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.261 seconds; current allocated memory: 157.618 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.912 seconds; current allocated memory: 165.947 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:26 ; elapsed = 00:00:43 . Memory (MB): peak = 998.277 ; gain = 900.539
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 110.54 MHz
INFO: [HLS 200-112] Total elapsed time: 43.231 seconds; peak allocated memory: 165.947 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.5ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.5ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:62:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:15 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:61)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:17 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:19 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 26.136 seconds; current allocated memory: 151.778 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.494 seconds; current allocated memory: 157.707 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.731 seconds; current allocated memory: 165.991 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:42 . Memory (MB): peak = 997.457 ; gain = 899.723
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 109.59 MHz
INFO: [HLS 200-112] Total elapsed time: 41.801 seconds; peak allocated memory: 165.991 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:62:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 8.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 8.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:61)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:22 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][7]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:20 ; elapsed = 00:00:35 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-303] Cannot apply memory assignment of 'RAM_T2P_BRAM': '' does not exist or is optimized away.
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_5_0_load_3', lenet_proj/lenet_top.cpp:47) on array 'padded[5][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_5_0'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_5_6_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[5][6]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_5_6'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_1_load_6', lenet_proj/lenet_top.cpp:47) on array 'padded[0][1]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_1'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_6_1_load_19', lenet_proj/lenet_top.cpp:47) on array 'padded[6][1]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_6_1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 11, Depth = 144.
WARNING: [HLS 200-871] Estimated clock period (15.7207ns) exceeds the target (target clock period: 12.6ns, clock uncertainty: 3.402ns, effective delay budget: 9.198ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'phi' operation ('indvar_flatten11', lenet_proj/lenet_top.cpp:40) with incoming values : ('select_ln40_15', lenet_proj/lenet_top.cpp:40) [770]  (0 ns)
	'icmp' operation ('icmp_ln40', lenet_proj/lenet_top.cpp:40) [805]  (1.77 ns)
	'select' operation ('select_ln39', lenet_proj/lenet_top.cpp:39) [806]  (1.22 ns)
	'add' operation ('add_ln40', lenet_proj/lenet_top.cpp:40) [877]  (1.78 ns)
	'select' operation ('select_ln40_3', lenet_proj/lenet_top.cpp:40) [889]  (0.993 ns)
	'getelementptr' operation ('padded_5_2_addr_2', lenet_proj/lenet_top.cpp:47) [1104]  (0 ns)
	'load' operation ('padded_5_2_load', lenet_proj/lenet_top.cpp:47) on array 'padded[5][2]', lenet_proj/lenet_top.cpp:24 [1205]  (3.25 ns)
	blocking operation 6.71 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 67.683 seconds; current allocated memory: 183.128 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_7' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 4.449 seconds; current allocated memory: 203.030 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_647_32_1_1': 15 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_864_32_1_1': 42 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.308 seconds; current allocated memory: 220.812 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM_T2P_BRAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:09 ; elapsed = 00:01:36 . Memory (MB): peak = 998.309 ; gain = 900.602
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 63.61 MHz
INFO: [HLS 200-112] Total elapsed time: 96.438 seconds; peak allocated memory: 220.812 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:62:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 8.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 8.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][7]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][0]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[4][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[5][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[6][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][1]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][2]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][3]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][4]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][5]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][6]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[7][7]' in function 'lenet_top' (lenet_proj/lenet_top.cpp:47:40).
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:61)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:23 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[4][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[5][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[6][7]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][4]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][5]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][6]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[7][7]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:21 ; elapsed = 00:00:36 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-303] Cannot apply memory assignment of 'RAM_1P_LUTRAM': '' does not exist or is optimized away.
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_5_0_load_2', lenet_proj/lenet_top.cpp:47) on array 'padded[5][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_5_0'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_5_6_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[5][6]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_5_6'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_6_1_load_20', lenet_proj/lenet_top.cpp:47) on array 'padded[6][1]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_6_1'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_6_6_load_3', lenet_proj/lenet_top.cpp:47) on array 'padded[6][6]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_6_6'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 22, Depth = 144.
WARNING: [HLS 200-871] Estimated clock period (15.7207ns) exceeds the target (target clock period: 12.6ns, clock uncertainty: 3.402ns, effective delay budget: 9.198ns).
WARNING: [HLS 200-1016] The critical path in module 'lenet_top' consists of the following:	'phi' operation ('indvar_flatten11', lenet_proj/lenet_top.cpp:40) with incoming values : ('select_ln40_15', lenet_proj/lenet_top.cpp:40) [770]  (0 ns)
	'icmp' operation ('icmp_ln40', lenet_proj/lenet_top.cpp:40) [805]  (1.77 ns)
	'select' operation ('select_ln39', lenet_proj/lenet_top.cpp:39) [806]  (1.22 ns)
	'add' operation ('add_ln40', lenet_proj/lenet_top.cpp:40) [877]  (1.78 ns)
	'select' operation ('select_ln40_3', lenet_proj/lenet_top.cpp:40) [889]  (0.993 ns)
	'getelementptr' operation ('padded_1_1_addr_2', lenet_proj/lenet_top.cpp:47) [972]  (0 ns)
	'load' operation ('padded_1_1_load', lenet_proj/lenet_top.cpp:47) on array 'padded[1][1]', lenet_proj/lenet_top.cpp:24 [1300]  (2.32 ns)
	blocking operation 7.64 ns on control path)

INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 62.86 seconds; current allocated memory: 183.068 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_4_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_5_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_6_7' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_4' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_5' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_6' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_7_7' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 4.624 seconds; current allocated memory: 202.788 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_647_32_1_1': 15 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_864_32_1_1': 42 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.428 seconds; current allocated memory: 220.257 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:05 ; elapsed = 00:01:32 . Memory (MB): peak = 997.719 ; gain = 899.977
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 63.61 MHz
INFO: [HLS 200-112] Total elapsed time: 92.71 seconds; peak allocated memory: 220.257 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-178] Inlining function 'conv2d_layer(float (*) [28], float (*) [28][6], float (*) [5][1][6], float*)' into 'lenet_top(float (*) [28], float (*) [28][6])' (lenet_proj/lenet_top.cpp:62:0)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'lenet_top' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'lenet_top' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'lenet_top'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'lenet_top'.
INFO: [XFORM 203-11] Balancing expressions in function 'lenet_top' (lenet_proj/lenet_top.cpp:61)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'lenet_top'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'lenet_top'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:19 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 26.059 seconds; current allocated memory: 151.779 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.492 seconds; current allocated memory: 157.691 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.782 seconds; current allocated memory: 165.960 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:42 . Memory (MB): peak = 998.004 ; gain = 900.285
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 42.181 seconds; peak allocated memory: 165.960 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:14 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_top.cpp:24:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:19 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 25.513 seconds; current allocated memory: 161.532 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.589 seconds; current allocated memory: 167.423 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.122 seconds; current allocated memory: 167.777 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.199 seconds; current allocated memory: 167.966 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.895 seconds; current allocated memory: 175.823 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.76 seconds; current allocated memory: 192.850 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:43 . Memory (MB): peak = 997.297 ; gain = 899.578
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 43.405 seconds; peak allocated memory: 192.850 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:13 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_top.cpp:24:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:15 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:18 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 24.757 seconds; current allocated memory: 161.581 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.411 seconds; current allocated memory: 167.485 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.051 seconds; current allocated memory: 167.796 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.199 seconds; current allocated memory: 167.985 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.921 seconds; current allocated memory: 175.842 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.635 seconds; current allocated memory: 192.852 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:41 . Memory (MB): peak = 997.695 ; gain = 899.918
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 41.135 seconds; peak allocated memory: 192.852 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_top.cpp:29:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_top.cpp:32:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:14 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_33_2' (lenet_proj/lenet_top.cpp:33) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_41_5' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_44_6' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_45_7' (lenet_proj/lenet_top.cpp:43) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_top.cpp:24) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_top.cpp:24:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:16 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_32_1' (lenet_proj/lenet_top.cpp:32:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_40_4' (lenet_proj/lenet_top.cpp:40:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_39_3' (lenet_proj/lenet_top.cpp:39:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_top.cpp:34:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:19 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln53_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_32_1_VITIS_LOOP_33_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_39_3_VITIS_LOOP_40_4_VITIS_LOOP_41_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_top.cpp:47) on array 'padded[0][0]', lenet_proj/lenet_top.cpp:24 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 25.295 seconds; current allocated memory: 161.614 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.491 seconds; current allocated memory: 167.505 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.022 seconds; current allocated memory: 167.801 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 168.019 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.988 seconds; current allocated memory: 175.921 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.669 seconds; current allocated memory: 192.903 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:23 ; elapsed = 00:00:42 . Memory (MB): peak = 998.094 ; gain = 900.332
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 42.359 seconds; peak allocated memory: 192.903 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:20:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:19 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:19 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_21_2' (lenet_proj/lenet_support.cpp:21) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_29_5' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_32_6' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_7' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:12:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:21 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_20_1' (lenet_proj/lenet_support.cpp:20:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_4' (lenet_proj/lenet_support.cpp:28:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_27_3' (lenet_proj/lenet_support.cpp:27:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:22:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:24 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_20_1_VITIS_LOOP_21_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_27_3_VITIS_LOOP_28_4_VITIS_LOOP_29_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:35) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:12 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 30.203 seconds; current allocated memory: 161.658 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.447 seconds; current allocated memory: 167.549 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.015 seconds; current allocated memory: 167.860 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.199 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.973 seconds; current allocated memory: 175.964 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.62 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:47 . Memory (MB): peak = 998.105 ; gain = 900.379
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 46.728 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:20:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:18 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:18 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_21_2' (lenet_proj/lenet_support.cpp:21) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_29_5' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_32_6' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_7' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:12:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:21 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_20_1' (lenet_proj/lenet_support.cpp:20:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_4' (lenet_proj/lenet_support.cpp:28:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_27_3' (lenet_proj/lenet_support.cpp:27:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:22:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:23 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_20_1_VITIS_LOOP_21_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_27_3_VITIS_LOOP_28_4_VITIS_LOOP_29_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:35) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:12 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 30.159 seconds; current allocated memory: 161.657 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.43 seconds; current allocated memory: 167.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.022 seconds; current allocated memory: 167.859 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.201 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.88 seconds; current allocated memory: 175.963 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.623 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:47 . Memory (MB): peak = 997.109 ; gain = 899.352
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 47.402 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:20:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:19 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_21_2' (lenet_proj/lenet_support.cpp:21) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_29_5' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_32_6' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_7' (lenet_proj/lenet_support.cpp:31) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:12) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:12:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:21 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_20_1' (lenet_proj/lenet_support.cpp:20:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_4' (lenet_proj/lenet_support.cpp:28:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_27_3' (lenet_proj/lenet_support.cpp:27:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:22:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:24 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln41_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_20_1_VITIS_LOOP_21_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_27_3_VITIS_LOOP_28_4_VITIS_LOOP_29_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:35) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:12 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 30.219 seconds; current allocated memory: 161.657 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.449 seconds; current allocated memory: 167.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.014 seconds; current allocated memory: 167.859 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.199 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.942 seconds; current allocated memory: 175.963 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.616 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:24 ; elapsed = 00:00:47 . Memory (MB): peak = 998.062 ; gain = 900.324
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 47.43 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-3340] no matching function for call to 'conv2d_layer': lenet_proj/lenet_top.cpp:27:2
INFO: [HLS 207-4395] candidate function not viable: no known conversion from 'float [5][5][1][6]' to 'data_t (*)[5][1][6]' for 3rd argument: lenet_proj/lenet_top.h:19:6
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-812] 'lenet_top.h' file not found: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\ML_PATH_EE297\EE297_env\projects\weights\conv1_weights.h:1:10
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-3803] unknown type name 'data_t': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\ML_PATH_EE297\EE297_env\projects\weights\conv1_weights.h:1:1
ERROR: [HLS 207-3803] unknown type name 'data_t': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\ML_PATH_EE297\EE297_env\projects\weights\conv1_biases.h:1:1
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-812] 'lenet_top.h' file not found: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\ML_PATH_EE297\EE297_env\projects\weights\conv1_weights.h:1:10
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:17:9
ERROR: [HLS 207-2363] conditional expression is ambiguous; 'data_t' (aka 'ap_fixed<16, 8>') can be converted to 'int' and vice versa: lenet_proj/lenet_support.cpp:41:49
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:541:146)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' into 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed.h:183:59)
INFO: [HLS 214-131] Inlining function 'ap_int_base<65, true>::ap_int_base<11, false>(ap_int_base<11, false> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:341)
INFO: [HLS 214-131] Inlining function 'ap_int<65>::ap_int<65, true>(ap_int_base<65, true> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:555)
INFO: [HLS 214-131] Inlining function 'ap_int_base<65, true>::ap_int_base<64, true>(ap_int_base<64, true> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:430)
INFO: [HLS 214-131] Inlining function 'ap_int_base<64, true>::ap_int_base(long)' into 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1467:1548)
INFO: [HLS 214-131] Inlining function 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' into 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1467:1546)
INFO: [HLS 214-131] Inlining function 'ap_int_base<55, true>::ap_int_base<1, false>(ap_int_base<1, false> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:341)
INFO: [HLS 214-131] Inlining function 'ap_int<55>::ap_int<55, true>(ap_int_base<55, true> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:555)
INFO: [HLS 214-131] Inlining function 'ap_int_base<55, true>::ap_int_base<54, true>(ap_int_base<54, true> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:430)
INFO: [HLS 214-131] Inlining function 'ap_int_base<1, false>::ap_int_base(int)' into 'ap_int_base<54, true>::operator-() const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:750:12)
INFO: [HLS 214-131] Inlining function 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' into 'ap_int_base<54, true>::operator-() const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:750:37)
INFO: [HLS 214-131] Inlining function 'doubleToRawBits(double)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:556:14)
INFO: [HLS 214-131] Inlining function 'ap_int_base<54, true>& ap_int_base<54, true>::operator=<55, true>(ap_int_base<55, true> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:570:20)
INFO: [HLS 214-131] Inlining function 'ap_int_base<54, true>::operator-() const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:570:22)
INFO: [HLS 214-131] Inlining function 'ap_int_base<12, true>& ap_int_base<12, true>::operator=<65, true>(ap_int_base<65, true> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:563:9)
INFO: [HLS 214-131] Inlining function 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:563:19)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::mult ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator*<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1119:12)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:330)
INFO: [HLS 214-131] Inlining function 'ap_fixed<33, 17, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:382)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:342)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:248)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:246)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:330)
INFO: [HLS 214-131] Inlining function 'ap_fixed<17, 9, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:382)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:342)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::plus ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:248)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<17, 9, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:246)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<40, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'bool ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator><32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1494:367)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' into 'bool operator><16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:2221:9949)
INFO: [HLS 214-131] Inlining function 'bool ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator><32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'bool operator><16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:2221:9938)
INFO: [HLS 214-131] Inlining function 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:13:38)
INFO: [HLS 214-131] Inlining function 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:37)
INFO: [HLS 214-131] Inlining function 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:57)
INFO: [HLS 214-131] Inlining function 'bool operator><16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:44)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:41:21)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:38:29)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<16, 8, true>::mult ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator*<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<16, 8, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:38:38)
INFO: [HLS 214-131] Inlining function 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(double)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:32:15)
INFO: [HLS 214-131] Inlining function 'ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<16, 8, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 214-115] Burst read of length 784 and bit width 16 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:05 ; elapsed = 00:00:24 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:05 ; elapsed = 00:00:24 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:05 ; elapsed = 00:00:24 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:06 ; elapsed = 00:00:24 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:33) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:34) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded.V' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded.V' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:26 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0].V' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0].V' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:29 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_14) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_13) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_12) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_11) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_10) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_8) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_7) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_9) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_8) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_6) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_7) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_5) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_4) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_3) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_2) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_6) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_5) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_4) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_3) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_2) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1192) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln703) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln1118) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_V_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0].V', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0_V'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 36.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 34.684 seconds; current allocated memory: 215.728 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3_V' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.26 seconds; current allocated memory: 220.640 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.976 seconds; current allocated memory: 220.711 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 220.877 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_7ns_16s_24ns_24_4_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_7s_16s_24ns_24_4_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_8s_16s_23s_24_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_8s_16s_24ns_24_4_1': 14 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_9s_16s_24ns_24_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_5ns_14_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_7s_16s_23_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_16_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.991 seconds; current allocated memory: 228.703 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.704 seconds; current allocated memory: 244.116 MB.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_5ns_14_1_1_Multiplier_0'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_V_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_V_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:52 . Memory (MB): peak = 998.832 ; gain = 901.109
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 52.575 seconds; peak allocated memory: 244.116 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:541:146)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' into 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed.h:183:59)
INFO: [HLS 214-131] Inlining function 'ap_int_base<65, true>::ap_int_base<11, false>(ap_int_base<11, false> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:341)
INFO: [HLS 214-131] Inlining function 'ap_int<65>::ap_int<65, true>(ap_int_base<65, true> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:555)
INFO: [HLS 214-131] Inlining function 'ap_int_base<65, true>::ap_int_base<64, true>(ap_int_base<64, true> const&)' into 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:430)
INFO: [HLS 214-131] Inlining function 'ap_int_base<64, true>::ap_int_base(long)' into 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1467:1548)
INFO: [HLS 214-131] Inlining function 'ap_int_base<11, false>::RType<64, true>::minus operator-<11, false, 64, true>(ap_int_base<11, false> const&, ap_int_base<64, true> const&)' into 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1467:1546)
INFO: [HLS 214-131] Inlining function 'ap_int_base<55, true>::ap_int_base<1, false>(ap_int_base<1, false> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:341)
INFO: [HLS 214-131] Inlining function 'ap_int<55>::ap_int<55, true>(ap_int_base<55, true> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:555)
INFO: [HLS 214-131] Inlining function 'ap_int_base<55, true>::ap_int_base<54, true>(ap_int_base<54, true> const&)' into 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:1351:430)
INFO: [HLS 214-131] Inlining function 'ap_int_base<1, false>::ap_int_base(int)' into 'ap_int_base<54, true>::operator-() const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:750:12)
INFO: [HLS 214-131] Inlining function 'ap_int_base<1, false>::RType<54, true>::minus operator-<1, false, 54, true>(ap_int_base<1, false> const&, ap_int_base<54, true> const&)' into 'ap_int_base<54, true>::operator-() const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_int_base.h:750:37)
INFO: [HLS 214-131] Inlining function 'doubleToRawBits(double)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:556:14)
INFO: [HLS 214-131] Inlining function 'ap_int_base<54, true>& ap_int_base<54, true>::operator=<55, true>(ap_int_base<55, true> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:570:20)
INFO: [HLS 214-131] Inlining function 'ap_int_base<54, true>::operator-() const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:570:22)
INFO: [HLS 214-131] Inlining function 'ap_int_base<12, true>& ap_int_base<12, true>::operator=<65, true>(ap_int_base<65, true> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:563:9)
INFO: [HLS 214-131] Inlining function 'ap_int_base<11, false>::RType<($_0)64, true>::minus operator-<11, false>(ap_int_base<11, false> const&, long)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(double)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:563:19)
INFO: [HLS 214-131] Inlining function 'ap_fixed<64, 32, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::mult ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator*<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1119:12)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<64, 32, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:330)
INFO: [HLS 214-131] Inlining function 'ap_fixed<65, 33, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<64, 32, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:382)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<64, 32, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:342)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<64, 32, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:248)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<65, 33, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:246)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:330)
INFO: [HLS 214-131] Inlining function 'ap_fixed<33, 17, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:382)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1192:342)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::plus ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:248)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<33, 17, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1212:246)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator!() const' into 'ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:698:9)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:431:5)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<48, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'bool ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator><32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:1494:367)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed_base(int)' into 'bool operator><32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:2221:9949)
INFO: [HLS 214-131] Inlining function 'bool ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator><32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'bool operator><32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' (Z:/Vitis/2020.1/common/technology/autopilot\ap_fixed_base.h:2221:9938)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:13:38)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:37)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(int)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:57)
INFO: [HLS 214-131] Inlining function 'bool operator><32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&, int)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:42:44)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:41:21)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>& ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator+=<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<64, 32, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:38:29)
INFO: [HLS 214-131] Inlining function 'ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::RType<32, 16, true>::mult ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>::operator*<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0>(ap_fixed_base<32, 16, true, (ap_q_mode)5, (ap_o_mode)3, 0> const&) const' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:38:38)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::ap_fixed(double)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:32:15)
INFO: [HLS 214-131] Inlining function 'ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>::operator=(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> const&)' into 'conv2d_layer(ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [28][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> (*) [5][1][6], ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:33) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:34) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.V.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded.V' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded.V' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:27 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0].V' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0].V' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:30 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln205) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln205_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_V_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0].V', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0_V'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 34.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 35.079 seconds; current allocated memory: 215.358 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2_V' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3_V' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.158 seconds; current allocated memory: 220.175 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.984 seconds; current allocated memory: 220.231 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.241 seconds; current allocated memory: 220.397 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'mul_15ns_32s_47_1_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_15s_32s_47_1_1': 5 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_16s_32s_48_1_1': 15 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_17s_32s_48_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.021 seconds; current allocated memory: 228.067 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.825 seconds; current allocated memory: 243.985 MB.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_15s_32s_47_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_16s_32s_48_1_1_Multiplier_1'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_17s_32s_48_1_1_Multiplier_2'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_15ns_32s_47_1_1_Multiplier_3'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_V_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_V_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_V_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:53 . Memory (MB): peak = 997.328 ; gain = 899.660
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 52.792 seconds; peak allocated memory: 243.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:25 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:25 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:25 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:25 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:27 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:30 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 37.026 seconds; current allocated memory: 161.657 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.751 seconds; current allocated memory: 167.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.119 seconds; current allocated memory: 167.859 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.223 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.076 seconds; current allocated memory: 175.964 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 5.083 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:26 ; elapsed = 00:00:56 . Memory (MB): peak = 997.887 ; gain = 912.555
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 56.638 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:23 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:26 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 32.992 seconds; current allocated memory: 161.657 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.539 seconds; current allocated memory: 167.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.048 seconds; current allocated memory: 167.859 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.209 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.091 seconds; current allocated memory: 175.964 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.771 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:26 ; elapsed = 00:00:51 . Memory (MB): peak = 997.922 ; gain = 900.203
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 51.498 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:22 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:25 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 32.125 seconds; current allocated memory: 161.657 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.476 seconds; current allocated memory: 167.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.036 seconds; current allocated memory: 167.859 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 168.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.919 seconds; current allocated memory: 175.963 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 4.736 seconds; current allocated memory: 192.985 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:25 ; elapsed = 00:00:50 . Memory (MB): peak = 998.234 ; gain = 900.477
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 50.289 seconds; peak allocated memory: 192.985 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:22 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:25 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 31.692 seconds; current allocated memory: 172.177 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.423 seconds; current allocated memory: 178.053 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.22 seconds; current allocated memory: 178.872 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.238 seconds; current allocated memory: 179.670 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.264 seconds; current allocated memory: 179.831 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.385 seconds; current allocated memory: 180.213 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.978 seconds; current allocated memory: 188.175 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.689 seconds; current allocated memory: 205.799 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.045 seconds; current allocated memory: 209.337 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:26 ; elapsed = 00:00:51 . Memory (MB): peak = 997.656 ; gain = 899.941
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 51.286 seconds; peak allocated memory: 209.337 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-124] use of undeclared identifier 'conv2_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:41
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:19 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:19 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv2_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:43)...4 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:23 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:11 ; elapsed = 00:00:28 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 34.952 seconds; current allocated memory: 193.781 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.463 seconds; current allocated memory: 199.664 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.232 seconds; current allocated memory: 200.497 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.251 seconds; current allocated memory: 201.281 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_83_1_VITIS_LOOP_84_2_VITIS_LOOP_85_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:92) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 150, Depth = 780.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 15.275 seconds; current allocated memory: 209.532 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.475 seconds; current allocated memory: 226.222 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.034 seconds; current allocated memory: 227.265 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.814 seconds; current allocated memory: 228.269 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.376 seconds; current allocated memory: 236.568 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.688 seconds; current allocated memory: 254.137 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 6.482 seconds; current allocated memory: 277.859 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 8.377 seconds; current allocated memory: 307.771 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_1_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_3_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_0_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_1_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_2_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_3_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_0_4_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_0_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_1_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_2_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_3_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_1_4_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_0_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_1_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_2_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_3_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_2_4_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_0_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_1_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_2_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_3_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_3_4_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_0_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_1_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_2_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_3_5_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_4_4_5_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:20 ; elapsed = 00:02:04 . Memory (MB): peak = 998.285 ; gain = 900.664
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 94.74 MHz
INFO: [HLS 200-112] Total elapsed time: 124.277 seconds; peak allocated memory: 307.771 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:22 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:23) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:23) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:23) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:26 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 32.707 seconds; current allocated memory: 181.070 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.482 seconds; current allocated memory: 186.953 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.235 seconds; current allocated memory: 187.786 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.239 seconds; current allocated memory: 188.570 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.455 seconds; current allocated memory: 189.143 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.249 seconds; current allocated memory: 189.777 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.272 seconds; current allocated memory: 189.940 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.544 seconds; current allocated memory: 190.509 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.032 seconds; current allocated memory: 198.552 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.74 seconds; current allocated memory: 216.022 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.057 seconds; current allocated memory: 219.896 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.949 seconds; current allocated memory: 223.204 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:29 ; elapsed = 00:00:55 . Memory (MB): peak = 988.828 ; gain = 891.090
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 55.655 seconds; peak allocated memory: 223.204 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:24 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:27 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 33.704 seconds; current allocated memory: 181.071 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.499 seconds; current allocated memory: 186.939 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.255 seconds; current allocated memory: 187.787 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 188.555 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.45 seconds; current allocated memory: 189.128 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.253 seconds; current allocated memory: 189.778 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.265 seconds; current allocated memory: 189.941 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 190.495 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.105 seconds; current allocated memory: 198.553 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.691 seconds; current allocated memory: 216.024 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.048 seconds; current allocated memory: 219.926 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.942 seconds; current allocated memory: 223.189 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:29 ; elapsed = 00:00:56 . Memory (MB): peak = 997.617 ; gain = 879.473
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 56.304 seconds; peak allocated memory: 223.189 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:22 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:25 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 32.08 seconds; current allocated memory: 181.071 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.436 seconds; current allocated memory: 186.939 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.232 seconds; current allocated memory: 187.787 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.243 seconds; current allocated memory: 188.555 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.452 seconds; current allocated memory: 189.128 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.251 seconds; current allocated memory: 189.778 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.279 seconds; current allocated memory: 189.941 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.558 seconds; current allocated memory: 190.495 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.042 seconds; current allocated memory: 198.553 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.668 seconds; current allocated memory: 216.024 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.052 seconds; current allocated memory: 219.926 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.938 seconds; current allocated memory: 223.189 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:29 ; elapsed = 00:00:54 . Memory (MB): peak = 997.719 ; gain = 899.961
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 54.661 seconds; peak allocated memory: 223.189 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:03 ; elapsed = 00:00:20 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:23 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:26 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 32.824 seconds; current allocated memory: 181.071 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.449 seconds; current allocated memory: 186.939 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.221 seconds; current allocated memory: 187.787 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.247 seconds; current allocated memory: 188.555 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.448 seconds; current allocated memory: 189.128 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.243 seconds; current allocated memory: 189.778 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.271 seconds; current allocated memory: 189.941 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 190.495 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.033 seconds; current allocated memory: 198.553 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.665 seconds; current allocated memory: 216.024 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.04 seconds; current allocated memory: 219.926 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.955 seconds; current allocated memory: 223.189 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:28 ; elapsed = 00:00:55 . Memory (MB): peak = 948.805 ; gain = 851.066
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 55.159 seconds; peak allocated memory: 223.189 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
ERROR: [HLS 207-3431] redefinition of 'maxpool2_layer': lenet_proj/lenet_support.cpp:131:6
INFO: [HLS 207-71] previous definition is here: lenet_proj/lenet_support.cpp:106:6
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:140:24
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:23 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:8) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:27 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 33.769 seconds; current allocated memory: 192.086 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.448 seconds; current allocated memory: 197.932 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.33 seconds; current allocated memory: 198.781 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.351 seconds; current allocated memory: 199.549 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.455 seconds; current allocated memory: 200.122 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.261 seconds; current allocated memory: 200.772 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.409 seconds; current allocated memory: 201.356 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 202.082 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 202.263 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.709 seconds; current allocated memory: 203.019 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.096 seconds; current allocated memory: 211.102 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.706 seconds; current allocated memory: 228.602 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.06 seconds; current allocated memory: 232.454 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.887 seconds; current allocated memory: 235.990 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.08 seconds; current allocated memory: 239.860 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:31 ; elapsed = 00:00:59 . Memory (MB): peak = 997.086 ; gain = 899.367
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 58.994 seconds; peak allocated memory: 239.860 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:24 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:28 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 34.756 seconds; current allocated memory: 192.084 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.451 seconds; current allocated memory: 197.931 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.258 seconds; current allocated memory: 198.780 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.253 seconds; current allocated memory: 199.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.465 seconds; current allocated memory: 200.121 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.267 seconds; current allocated memory: 200.770 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.445 seconds; current allocated memory: 201.354 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.244 seconds; current allocated memory: 202.081 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.273 seconds; current allocated memory: 202.261 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.728 seconds; current allocated memory: 203.018 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.101 seconds; current allocated memory: 211.101 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.756 seconds; current allocated memory: 228.601 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.04 seconds; current allocated memory: 232.453 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.888 seconds; current allocated memory: 235.989 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.096 seconds; current allocated memory: 239.858 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:31 ; elapsed = 00:01:00 . Memory (MB): peak = 998.004 ; gain = 900.223
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 60.094 seconds; peak allocated memory: 239.858 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:23 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:27 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 33.991 seconds; current allocated memory: 192.084 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.423 seconds; current allocated memory: 197.931 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.23 seconds; current allocated memory: 198.780 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.244 seconds; current allocated memory: 199.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.441 seconds; current allocated memory: 200.121 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.245 seconds; current allocated memory: 200.770 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.419 seconds; current allocated memory: 201.354 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.241 seconds; current allocated memory: 202.081 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.273 seconds; current allocated memory: 202.261 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.704 seconds; current allocated memory: 203.018 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.094 seconds; current allocated memory: 211.101 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.729 seconds; current allocated memory: 228.601 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.065 seconds; current allocated memory: 232.453 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.885 seconds; current allocated memory: 235.989 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.105 seconds; current allocated memory: 239.858 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:31 ; elapsed = 00:00:59 . Memory (MB): peak = 997.664 ; gain = 899.965
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 58.896 seconds; peak allocated memory: 239.858 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:23 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:27 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 34.179 seconds; current allocated memory: 192.084 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.479 seconds; current allocated memory: 197.931 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.229 seconds; current allocated memory: 198.780 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.242 seconds; current allocated memory: 199.548 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 200.121 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.251 seconds; current allocated memory: 200.770 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.432 seconds; current allocated memory: 201.354 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.236 seconds; current allocated memory: 202.081 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.268 seconds; current allocated memory: 202.261 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.708 seconds; current allocated memory: 203.018 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.169 seconds; current allocated memory: 211.101 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.714 seconds; current allocated memory: 228.601 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.039 seconds; current allocated memory: 232.453 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.906 seconds; current allocated memory: 235.989 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 1.087 seconds; current allocated memory: 239.858 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:32 ; elapsed = 00:00:59 . Memory (MB): peak = 998.305 ; gain = 900.602
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 59.422 seconds; peak allocated memory: 239.858 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
ERROR: [SIM 211-100] CSim file generation failed: compilation error(s).
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-123] expected unqualified-id: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:27
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:29
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:30
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:31
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:32
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:33
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:34
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:36
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:37
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:38
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:39
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:40
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:41
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:42
ERROR: [HLS 214-124] use of undeclared identifier 'image': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'conv1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'pool1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
ERROR: [HLS 214-124] use of undeclared identifier 'conv2_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-123] expected unqualified-id: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:27
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:29
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:30
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:31
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:32
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:33
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:34
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:36
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:37
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:38
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:39
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:40
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:41
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:42
ERROR: [HLS 214-124] use of undeclared identifier 'image': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'conv1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'pool1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
ERROR: [HLS 214-124] use of undeclared identifier 'conv2_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:20 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'flatten_layer' (lenet_proj/lenet_support.cpp:132)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:23 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:27 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 33.589 seconds; current allocated memory: 202.552 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.516 seconds; current allocated memory: 208.317 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.232 seconds; current allocated memory: 209.166 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.249 seconds; current allocated memory: 209.934 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 210.507 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.267 seconds; current allocated memory: 211.157 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.408 seconds; current allocated memory: 211.741 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.261 seconds; current allocated memory: 212.483 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 11.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 212.808 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.178 seconds; current allocated memory: 213.094 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.194 seconds; current allocated memory: 213.224 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.836 seconds; current allocated memory: 214.072 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.126 seconds; current allocated memory: 222.199 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.754 seconds; current allocated memory: 239.593 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.07 seconds; current allocated memory: 243.475 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.885 seconds; current allocated memory: 246.997 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.932 seconds; current allocated memory: 250.154 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.713 seconds; current allocated memory: 252.718 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:32 ; elapsed = 00:01:00 . Memory (MB): peak = 998.035 ; gain = 900.309
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 60.313 seconds; peak allocated memory: 252.718 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
WARNING: [HLS 214-167] The program may have out of bound array access (lenet_proj/lenet_support.cpp:142:20)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'flatten_layer' (lenet_proj/lenet_support.cpp:132)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:24 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:28 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 35.48 seconds; current allocated memory: 202.558 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.492 seconds; current allocated memory: 208.324 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.28 seconds; current allocated memory: 209.172 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.249 seconds; current allocated memory: 209.940 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.453 seconds; current allocated memory: 210.513 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.249 seconds; current allocated memory: 211.163 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.438 seconds; current allocated memory: 211.747 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 212.489 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 11.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.324 seconds; current allocated memory: 212.815 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.186 seconds; current allocated memory: 213.102 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.193 seconds; current allocated memory: 213.232 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.823 seconds; current allocated memory: 214.080 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.198 seconds; current allocated memory: 222.207 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.98 seconds; current allocated memory: 239.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.1 seconds; current allocated memory: 243.498 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.903 seconds; current allocated memory: 247.021 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.942 seconds; current allocated memory: 250.179 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.732 seconds; current allocated memory: 252.772 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:34 ; elapsed = 00:01:03 . Memory (MB): peak = 997.539 ; gain = 899.785
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 62.934 seconds; peak allocated memory: 252.772 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'flatten_layer' (lenet_proj/lenet_support.cpp:132)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:28 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 35.242 seconds; current allocated memory: 202.552 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.547 seconds; current allocated memory: 208.317 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.278 seconds; current allocated memory: 209.166 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.256 seconds; current allocated memory: 209.934 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.471 seconds; current allocated memory: 210.507 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.261 seconds; current allocated memory: 211.157 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.482 seconds; current allocated memory: 211.741 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.303 seconds; current allocated memory: 212.483 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 11.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 212.808 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.186 seconds; current allocated memory: 213.094 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.197 seconds; current allocated memory: 213.224 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.849 seconds; current allocated memory: 214.072 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.173 seconds; current allocated memory: 222.199 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 5.161 seconds; current allocated memory: 239.593 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.224 seconds; current allocated memory: 243.475 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.108 seconds; current allocated memory: 246.997 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.113 seconds; current allocated memory: 250.154 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.796 seconds; current allocated memory: 252.718 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:33 ; elapsed = 00:01:04 . Memory (MB): peak = 997.004 ; gain = 899.309
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 63.799 seconds; peak allocated memory: 252.718 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
WARNING: [HLS 214-167] The program may have out of bound array access (lenet_proj/lenet_support.cpp:142:20)
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:22 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'flatten_layer' (lenet_proj/lenet_support.cpp:132)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:25 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:29 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 36.04 seconds; current allocated memory: 202.558 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.519 seconds; current allocated memory: 208.324 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.243 seconds; current allocated memory: 209.172 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.249 seconds; current allocated memory: 209.940 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.458 seconds; current allocated memory: 210.513 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.258 seconds; current allocated memory: 211.163 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.431 seconds; current allocated memory: 211.747 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.277 seconds; current allocated memory: 212.489 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 11.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 212.815 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 213.102 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.198 seconds; current allocated memory: 213.232 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.821 seconds; current allocated memory: 214.080 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.144 seconds; current allocated memory: 222.207 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.762 seconds; current allocated memory: 239.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.091 seconds; current allocated memory: 243.498 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.899 seconds; current allocated memory: 247.021 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.952 seconds; current allocated memory: 250.180 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.728 seconds; current allocated memory: 252.772 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:34 ; elapsed = 00:01:04 . Memory (MB): peak = 997.344 ; gain = 899.656
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 64.5 seconds; peak allocated memory: 252.772 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst read of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:04 ; elapsed = 00:00:21 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:06 ; elapsed = 00:00:24 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:09 ; elapsed = 00:00:27 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 34.188 seconds; current allocated memory: 202.338 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.416 seconds; current allocated memory: 208.103 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.221 seconds; current allocated memory: 208.952 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.257 seconds; current allocated memory: 209.720 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_1', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.446 seconds; current allocated memory: 210.308 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.241 seconds; current allocated memory: 210.943 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.425 seconds; current allocated memory: 211.527 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.238 seconds; current allocated memory: 212.269 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.301 seconds; current allocated memory: 212.467 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.164 seconds; current allocated memory: 212.658 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.162 seconds; current allocated memory: 212.751 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.797 seconds; current allocated memory: 213.583 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.087 seconds; current allocated memory: 221.658 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.711 seconds; current allocated memory: 239.104 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.054 seconds; current allocated memory: 242.986 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.882 seconds; current allocated memory: 246.493 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.914 seconds; current allocated memory: 249.370 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.565 seconds; current allocated memory: 251.401 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:32 ; elapsed = 00:01:00 . Memory (MB): peak = 998.016 ; gain = 900.285
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 59.95 seconds; peak allocated memory: 251.401 MB.
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
INFO: [SIM 211-1] CSim file generation done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-124] use of undeclared identifier 'IN_SIZE': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:59
ERROR: [HLS 214-124] use of undeclared identifier 'OUT_SIZE': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:60
ERROR: [HLS 214-124] use of undeclared identifier 'IN_SIZE': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:61
ERROR: [HLS 214-124] use of undeclared identifier 'OUT_SIZE': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:61
ERROR: [HLS 214-124] use of undeclared identifier 'OUT_SIZE': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:62
ERROR: [HLS 214-123] expected unqualified-id: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:27
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:29
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:30
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:31
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:32
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:33
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:34
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:36
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:37
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:38
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:39
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:40
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:41
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:42
ERROR: [HLS 214-124] use of undeclared identifier 'image': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'conv1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'pool1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
ERROR: [HLS 214-124] use of undeclared identifier 'conv2_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:53
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-123] expected unqualified-id: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:28
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:30
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:32
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:33
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:34
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:35
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:36
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:37
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:39
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:40
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:41
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:42
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:43
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:44
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:45
ERROR: [HLS 214-122] '#pragma HLS' is only allowed in function scope: C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:47
ERROR: [HLS 214-124] use of undeclared identifier 'image': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:52
ERROR: [HLS 214-124] use of undeclared identifier 'conv1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:52
ERROR: [HLS 214-124] use of undeclared identifier 'pool1_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:58
ERROR: [HLS 214-124] use of undeclared identifier 'conv2_out': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:58
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 214-124] use of undeclared identifier 'fc1_weights': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:67
ERROR: [HLS 214-124] use of undeclared identifier 'fc1_biases': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.cpp:67
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
ERROR: [HLS 207-812] 'C:\Users\Baron\Desktop\EE_297_Repo\EE_297\ML_PATH_EE297\EE297_env\projects\weights\fc3weights.h' file not found: lenet_proj/lenet_top.cpp:17:10
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:159:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
ERROR: [HLS 214-194] in function 'lenet_top(float (*) [28], float (*) [28][6], float (*) [14][6], float (*) [10][16], float (*) [5][16], float*, float*)': Undefined function fc_layer<400, 120> (lenet_proj/lenet_top.cpp:77:5)
ERROR: [HLS 214-135] Syn check fail!
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:159:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
ERROR: [HLS 214-194] in function 'lenet_top(float (*) [28], float (*) [28][6], float (*) [14][6], float (*) [10][16], float (*) [5][16], float*, float*)': Undefined function fc_layer<400, 120> (lenet_proj/lenet_top.cpp:77:5)
ERROR: [HLS 214-135] Syn check fail!
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:68:24
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_top.h:68:24
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
ERROR: [HLS 207-3431] redefinition of 'fc_layer': lenet_proj/lenet_support.cpp:150:6
INFO: [HLS 207-71] previous definition is here: lenet_proj/lenet_top.h:59:10
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:159:24
==============================================================
Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2020.1 (64-bit)
Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 12.6ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [HLS 200-1505] Using flow_target 'vivado'
WARNING: [HLS 200-40] Skipped source file 'img_5.txt'. Source files must have extensions .c, .C, .cc, .cpp, .c++, .cp, or .cxx.
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_top.cpp' ... 
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:68:24
INFO: [HLS 200-10] Analyzing design file 'lenet_proj/lenet_support.cpp' ... 
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_top.h:68:24
WARNING: [HLS 207-1535] 'Resource' is deprecated, and it will be removed in future release: lenet_proj/lenet_support.cpp:18:9
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:86:24
WARNING: [HLS 207-1600] unexpected pragma argument '', expect '=': lenet_proj/lenet_support.cpp:141:24
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-115] Burst read of length 784 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:21:19)
INFO: [HLS 214-115] Burst read of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 214-115] Burst write of length 400 and bit width 32 has been inferred on port 'gmem' (lenet_proj/lenet_support.cpp:138:23)
INFO: [HLS 214-115] Burst write of length 120 and bit width 32 has been inferred on port 'gmem' (C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:67:19)
INFO: [HLS 214-115] Burst read of length 400 and bit width 32 has been inferred on port 'gmem' (C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:70:30)
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:04 ; elapsed = 00:00:23 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:04 ; elapsed = 00:00:23 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:04 ; elapsed = 00:00:24 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:05 ; elapsed = 00:00:24 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_91_6' (lenet_proj/lenet_support.cpp:87) in function 'conv2d_6to16_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2' in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_22_2' (lenet_proj/lenet_support.cpp:22) in function 'conv2d_layer' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_70_2' (C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:69) in function 'fc_layer<400, 120>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'VITIS_LOOP_140_3' (lenet_proj/lenet_support.cpp:140) in function 'flatten_layer' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'VITIS_LOOP_30_5' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_33_6' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'VITIS_LOOP_34_7' (lenet_proj/lenet_support.cpp:32) in function 'conv2d_layer' completely with a factor of 5.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.0.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.1.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.2.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.3.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv1_weights.4.4' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 1 with a block factor 4.
INFO: [XFORM 203-101] Partitioning array 'padded' (lenet_proj/lenet_support.cpp:13) in dimension 2 with a block factor 4.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[0][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[1][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[2][3]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][0]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][1]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][2]' in function 'conv2d_layer'.
WARNING: [ANALYSIS 214-31] The program may have out of bound access of array variable 'padded[3][3]' in function 'conv2d_layer'.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool_layer' (lenet_proj/lenet_support.cpp:50)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'maxpool2_layer' (lenet_proj/lenet_support.cpp:107)...4 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_layer' (lenet_proj/lenet_support.cpp:13:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'conv2d_6to16_layer' (lenet_proj/lenet_support.cpp:83:69)...7 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:07 ; elapsed = 00:00:27 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_56_2' (lenet_proj/lenet_support.cpp:56:35) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_55_1' (lenet_proj/lenet_support.cpp:55:28) in function 'maxpool_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_113_2' (lenet_proj/lenet_support.cpp:113:36) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_112_1' (lenet_proj/lenet_support.cpp:112:29) in function 'maxpool2_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_139_2' (lenet_proj/lenet_support.cpp:139:36) in function 'flatten_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_138_1' (lenet_proj/lenet_support.cpp:138:32) in function 'flatten_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_67_1' (C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:69:9) in function 'fc_layer<400, 120>' the outer loop is not a perfect loop.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_21_1' (lenet_proj/lenet_support.cpp:21:28) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_29_4' (lenet_proj/lenet_support.cpp:29:35) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_28_3' (lenet_proj/lenet_support.cpp:28:31) in function 'conv2d_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_90_5' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_89_4' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer'.
WARNING: [HLS 200-960] Cannot flatten loop 'VITIS_LOOP_85_3' (lenet_proj/lenet_support.cpp:87:9) in function 'conv2d_6to16_layer' the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_84_2' (lenet_proj/lenet_support.cpp:84:35) in function 'conv2d_6to16_layer'.
INFO: [XFORM 203-541] Flattening a loop nest 'VITIS_LOOP_83_1' (lenet_proj/lenet_support.cpp:83:28) in function 'conv2d_6to16_layer'.
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' (lenet_proj/lenet_support.cpp:23:34)
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[0][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[1][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[2][3]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][0]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][1]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][2]' 
INFO: [HLS 200-472] Inferring partial write operation for 'padded[3][3]' 
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:30 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'lenet_top' ...
WARNING: [SYN 201-103] Legalizing function name 'fc_layer<400, 120>' to 'fc_layer_400_120_s'.
WARNING: [SYN 201-107] Renaming port name 'lenet_top/image' to 'lenet_top/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln42_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_21_1_VITIS_LOOP_22_2'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_28_3_VITIS_LOOP_29_4_VITIS_LOOP_30_5'.
WARNING: [HLS 200-885] Unable to schedule 'load' operation ('padded_0_0_load_1', lenet_proj/lenet_support.cpp:36) on array 'padded[0][0]', lenet_proj/lenet_support.cpp:13 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'padded_0_0'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 25, Depth = 146.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 37.245 seconds; current allocated memory: 225.692 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_0_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_1_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_2_3' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_0' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_1' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_2' will be ignored if a simpler one can be used.
WARNING: [BIND 205-102] The specified resource core for memory 'padded_3_3' will be ignored if a simpler one can be used.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.481 seconds; current allocated memory: 231.384 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln61_1) to 3 in order to utilize available DSP registers.
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln59_1) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_55_1_VITIS_LOOP_56_2_VITIS_LOOP_57_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:60) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 28.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.274 seconds; current allocated memory: 232.217 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.257 seconds; current allocated memory: 232.985 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [HLS 200-486] Changing DSP48 latency (root=mul_ln90) to 3 in order to utilize available DSP registers.
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_89_4_VITIS_LOOP_90_5_VITIS_LOOP_91_6'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94) and 'fadd' operation ('sum_3', lenet_proj/lenet_support.cpp:94).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 21.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.468 seconds; current allocated memory: 233.558 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.255 seconds; current allocated memory: 234.208 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_112_1_VITIS_LOOP_113_2_VITIS_LOOP_114_3'.
WARNING: [HLS 200-885] Unable to schedule bus request on port 'gmem' (lenet_proj/lenet_support.cpp:117) due to limited memory ports. Please consider using a memory core with more ports or partitioning the array.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 4, Depth = 25.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.434 seconds; current allocated memory: 234.792 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.245 seconds; current allocated memory: 235.562 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_138_1_VITIS_LOOP_139_2_VITIS_LOOP_140_3'.
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 1, Depth = 3.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.314 seconds; current allocated memory: 235.733 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.167 seconds; current allocated memory: 235.923 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'fc_layer_400_120_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'VITIS_LOOP_70_2'.
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 1) between 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71) and 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 2) between 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71) and 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 3) between 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71) and 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71).
WARNING: [HLS 200-881] Unable to enforce a carried constraint (II = 4) between 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71) and 'fadd' operation ('sum', C:\Users\Baron\Desktop\EE_297_Repo\EE_297\vivado\lenet_proj\lenet_top.h:71).
INFO: [HLS 200-1470] Pipelining result : Target II = 1, Final II = 5, Depth = 20.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.276 seconds; current allocated memory: 236.170 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.221 seconds; current allocated memory: 236.520 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.205 seconds; current allocated memory: 236.689 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.905 seconds; current allocated memory: 237.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mux_165_32_1_1': 25 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.153 seconds; current allocated memory: 245.708 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_10ns_4ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_4ns_10ns_13_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_11ns_5ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_mul_5ns_11ns_15_4_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool_layer'.
INFO: [HLS 200-111]  Elapsed time: 4.762 seconds; current allocated memory: 263.089 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv2d_6to16_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_10ns_4ns_10s_14_4_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv2d_6to16_layer'.
INFO: [HLS 200-111]  Elapsed time: 1.062 seconds; current allocated memory: 266.897 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'maxpool2_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'maxpool2_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.896 seconds; current allocated memory: 270.450 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flatten_layer' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flatten_layer'.
INFO: [HLS 200-111]  Elapsed time: 0.929 seconds; current allocated memory: 273.335 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'fc_layer_400_120_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'fadd_32ns_32ns_32_5_full_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fcmp_32ns_32ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'fmul_32ns_32ns_32_4_max_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'fc_layer_400_120_s'.
INFO: [HLS 200-111]  Elapsed time: 0.551 seconds; current allocated memory: 274.597 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'lenet_top' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Design contains AXI ports. Reset is fixed to synchronous and active low.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/gmem' to 'm_axi'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/image_r' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/conv2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/pool2_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/flat_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'lenet_top/fc1_out' to 's_axilite & ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on function 'lenet_top' to 's_axilite & ap_ctrl_hs'.
INFO: [RTGEN 206-100] Bundling port 'image_r', 'conv1_out', 'pool1_out', 'conv2_out', 'pool2_out', 'flat_out', 'fc1_out' to AXI-Lite port control.
INFO: [RTGEN 206-100] Finished creating RTL model for 'lenet_top'.
INFO: [HLS 200-111]  Elapsed time: 0.826 seconds; current allocated memory: 277.390 MB.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_0_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_1_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_2_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_3_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_0_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_1_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_2_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_3_0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_layer_conv1_weights_4_4_0_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'lenet_top_conv2d_layer_padded_0_0_ram (RAM_1P_LUTRAM)' using distributed RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_4ns_10ns_13_1_1_Multiplier_0'
INFO: [RTMG 210-282] Generating pipelined core: 'lenet_top_mul_10ns_4ns_13_1_1_Multiplier_1'
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_conv2d_6to16_layer_conv2_biases_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_fc_layer_400_120_s_fc1_biases_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'lenet_top_fc_layer_400_120_s_fc1_weights_rom' using auto ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:39 ; elapsed = 00:01:11 . Memory (MB): peak = 997.707 ; gain = 899.988
INFO: [VHDL 208-304] Generating VHDL RTL for lenet_top.
INFO: [VLOG 209-307] Generating Verilog RTL for lenet_top.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 108.72 MHz
INFO: [HLS 200-112] Total elapsed time: 71.352 seconds; peak allocated memory: 277.390 MB.
